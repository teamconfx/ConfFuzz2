note	bugId	status	times	testName	failure	failureMessage	stackTrace	reproStatus	replayedFailure	replayedErrorMessage	replayedStackTrace	replayedFile	minConfig	debugFiles											
	Bug-170	BUG	1	org.apache.hadoop.fs.TestFsShellCopy#testCopyCrc	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:495), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.shellRun(TestFsShellCopy.java:81), org.apache.hadoop.fs.TestFsShellCopy.testCopyCrc(TestFsShellCopy.java:98), org.apache.hadoop.fs.TestFsShellCopy.testCopyCrc$$CONFUZZ(TestFsShellCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyCrc/campaign/failures/debug_000001	{"file.stream-buffer-size": "667974771", "io.file.buffer.size": "2036062541"}	["debug_000001"]											
	Bug-199	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testTwoEntriesKnownLength	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength(TestTFileStreams.java:146), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testTwoEntriesKnownLength$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testTwoEntriesKnownLength/campaign/failures/debug_000002	{"tfile.fs.input.buffer.size": "1889678006", "file.bytes-per-checksum": "2010178645"}	["debug_000002"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestRPC#testDecayRpcSchedulerMetrics	java.lang.IllegalArgumentException	responseTimeThresholds must match with the number of priority levels	org.apache.hadoop.ipc.DecayRpcScheduler.parseBackOffResponseTimeThreshold(DecayRpcScheduler.java:397), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:235), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createScheduler(CallQueueManager.java:111), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.setupDecayRpcSchedulerandTestServer(TestRPC.java:1538), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics(TestRPC.java:1423), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testDecayRpcSchedulerMetrics/campaign/failures/debug_000000	{"ipc.0.faircallqueue.priority-levels": "5171"}	["debug_000000"]											
this factor value can't be negative	invalid value	FP	1	org.apache.hadoop.ipc.TestRPC#testDecayRpcSchedulerMetrics	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createScheduler(CallQueueManager.java:111), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.setupDecayRpcSchedulerandTestServer(TestRPC.java:1538), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics(TestRPC.java:1423), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testDecayRpcSchedulerMetrics/campaign/failures/debug_000001	{"ipc.0.decay-scheduler.decay-factor": "-0.30425095558166504"}	["debug_000001"]											
file.bytes-per-checksum	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:108), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testNoDataEntry$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testNoDataEntry/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2118552790", "io.file.buffer.size": "1771238085", "tfile.fs.output.buffer.size": "1639122022"}	["debug_000002"]											
this also have a null pointer when run the second time of the test. java.lang.NullPointerException         at org.apache.hadoop.http.TestHttpServer.cleanup(TestHttpServer.java:162)         at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)         at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)         at java.base/java.lang.reflect.Method.invoke(Method.java:566) 	Bug-10, Bug-11	BUG	1	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000003	{"hadoop.http.acceptor.count": "517839155", "hadoop.http.selector.count": "1211070682"}	["debug_000003"]											
	Bug-200,Bug-201	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:125), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2098119860", "tfile.io.chunk.size": "1843964018", "tfile.fs.output.buffer.size": "1007353131"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesIfMaxAttemptsNotSet	org.mockito.exceptions.verification.TooManyActualInvocations		org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesIfMaxAttemptsNotSet/campaign/failures/debug_000001	{"hadoop.security.kms.client.failover.sleep.base.millis": "0", "hadoop.security.kms.client.failover.max.retries": "23340"}	["debug_000001"]											
	Bug-171	BUG	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyPastEOF	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testReadFullyPastEOF(AbstractContractSeekTest.java:472), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testReadFullyPastEOF$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyPastEOF/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1540211550", "file.stream-buffer-size": "1525196485"}	["debug_000001"]											
		Non-Reproducible	1	org.apache.hadoop.fs.TestFileContextResolveAfs#testFileContextResolveAfs	java.io.IOException	Error 1 creating symlink file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/TestFileContextResolveAfs2 to /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/TestFileContextResolveAfs1	org.apache.hadoop.fs.RawLocalFileSystem.createSymlink(RawLocalFileSystem.java:1061), org.apache.hadoop.fs.DelegateToFileSystem.createSymlink(DelegateToFileSystem.java:249), org.apache.hadoop.fs.FilterFs.createSymlink(FilterFs.java:304), org.apache.hadoop.fs.FileContext$21.next(FileContext.java:1575), org.apache.hadoop.fs.FileContext$21.next(FileContext.java:1571), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.createSymlink(FileContext.java:1578), org.apache.hadoop.fs.TestFileContextResolveAfs.testFileContextResolveAfs(TestFileContextResolveAfs.java:61), org.apache.hadoop.fs.TestFileContextResolveAfs.testFileContextResolveAfs$$CONFUZZ(TestFileContextResolveAfs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileContextResolveAfs/testFileContextResolveAfs/campaign/failures/debug_000000	{}	["debug_000000"]											
	Bug-200	BUG	1	org.apache.hadoop.fs.TestLocalFileSystem#testStripFragmentFromPath	java.lang.OutOfMemoryError	Requested array size exceeds VM limit	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath(TestLocalFileSystem.java:640), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath$$CONFUZZ(TestLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFileSystem/testStripFragmentFromPath/campaign/failures/debug_000001	{"fs.file.impl.disable.cache": "true", "file.stream-buffer-size": "2147483646"}	["debug_000001"]											
	Bug-191	BUG	1	org.apache.hadoop.ipc.TestMultipleProtocolServer#testPBService	java.lang.ClassCastException	class org.apache.hadoop.ipc.RpcException cannot be cast to class org.apache.hadoop.ipc.RemoteException (org.apache.hadoop.ipc.RpcException and org.apache.hadoop.ipc.RemoteException are in unnamed module of loader 'app')	org.apache.hadoop.ipc.TestProtoBufRpc.testProtoBufRpc(TestProtoBufRpc.java:256), org.apache.hadoop.ipc.TestMultipleProtocolServer.testPBService(TestMultipleProtocolServer.java:66), org.apache.hadoop.ipc.TestMultipleProtocolServer.testPBService$$CONFUZZ(TestMultipleProtocolServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestMultipleProtocolServer/testPBService/campaign/failures/debug_000002	{"ipc.maximum.response.length": "1023"}	["debug_000002"]											
aggregation cost is different so that priority is different	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<1> but was:<2>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:311), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000000	{"ipc.15.weighted-cost.lockshared": "134479872"}	["debug_000000"]											
aggregation cost is different so that priority is different	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<2> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:312), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000006	{"ipc.15.weighted-cost.lockfree": "30203", "ipc.15.weighted-cost.lockexclusive": "9407", "ipc.15.faircallqueue.decay-scheduler.decay-factor": "0.22729027271270752", "ipc.15.weighted-cost.lockshared": "1609"}	["debug_000006"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.getSchedulerWithWeightedTimeCostProvider(TestDecayRpcScheduler.java:390), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:290), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000001	{"ipc.15.decay-scheduler.decay-factor": "-0.3755277991294861"}	["debug_000001"]											
	Bug-192	BUG	1	org.apache.hadoop.ha.TestZKFailoverController#testBecomingActiveFails	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testBecomingActiveFails/campaign/failures/debug_000002	{"ipc.server.read.threadpool.size": "2130640638"}	["debug_000002"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:119), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000000	{"ipc.7.decay-scheduler.decay-factor": "0.0"}	["debug_000000", "debug_000004", "debug_000002", "debug_000001", "debug_000003"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestIPC#testInitialCallRetryCount	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.junit.Assert.assertFalse(Assert.java:75), org.apache.hadoop.ipc.TestIPC.testInitialCallRetryCount(TestIPC.java:1382), org.apache.hadoop.ipc.TestIPC.testInitialCallRetryCount$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testInitialCallRetryCount/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]											
	invalid value	FP	1	org.apache.hadoop.security.TestLdapGroupsMapping#testLdapReadTimeout	java.net.SocketException	Connection or outbound has closed	java.base/sun.security.ssl.SSLSocketImpl$AppOutputStream.write(SSLSocketImpl.java:1298), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.naming/com.sun.jndi.ldap.Connection.writeRequest(Connection.java:414), java.naming/com.sun.jndi.ldap.Connection.writeRequest(Connection.java:387), java.naming/com.sun.jndi.ldap.LdapClient.ldapBind(LdapClient.java:359), java.naming/com.sun.jndi.ldap.LdapClient.authenticate(LdapClient.java:214), java.naming/com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2895), java.naming/com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:348), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:266), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:226), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:284), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:185), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:115), java.naming/javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:730), java.naming/javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:305), java.naming/javax.naming.InitialContext.init(InitialContext.java:236), java.naming/javax.naming.ldap.InitialLdapContext.<init>(InitialLdapContext.java:154), org.apache.hadoop.security.TestLdapGroupsMappingBase$DummyLdapCtxFactory.getInitialContext(TestLdapGroupsMappingBase.java:241), java.naming/javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:730), java.naming/javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:305), java.naming/javax.naming.InitialContext.init(InitialContext.java:236), java.naming/javax.naming.InitialContext.<init>(InitialContext.java:208), java.naming/javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101), org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:701), org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:512), org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:444), org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout$$CONFUZZ(TestLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMapping/testLdapReadTimeout/campaign/failures/debug_000001	{"hadoop.security.group.mapping.ldap.connection.timeout.ms": "0", "hadoop.security.group.mapping.ldap.ssl": "true"}	["debug_000001"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority(TestDecayRpcScheduler.java:215), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testPriority/campaign/failures/debug_000001	{"ipc.12.decay-scheduler.decay-factor": "-0.39996957778930664"}	["debug_000001"]											
	Bug-174	BUG	1	org.apache.hadoop.fs.TestHarFileSystemBasics#testListLocatedStatus	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testListLocatedStatus/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1659267637", "io.file.buffer.size": "1663809328"}	["debug_000001"]											
	Bug-172	BUG	1	org.apache.hadoop.io.TestArrayFile#testEmptyFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.ArrayFile$Writer.<init>(ArrayFile.java:45), org.apache.hadoop.io.TestArrayFile.writeTest(TestArrayFile.java:88), org.apache.hadoop.io.TestArrayFile.testEmptyFile(TestArrayFile.java:62), org.apache.hadoop.io.TestArrayFile.testEmptyFile$$CONFUZZ(TestArrayFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestArrayFile/testEmptyFile/campaign/failures/debug_000002	{"io.file.buffer.size": "1765730260", "file.bytes-per-checksum": "1625586761"}	["debug_000002"]											
	Bug-189	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureWriterNotClosed	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriterNotClosed(TestTFileByteArrays.java:256), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureWriterNotClosed$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureWriterNotClosed/campaign/failures/debug_000000	{"io.file.buffer.size": "914725398", "file.bytes-per-checksum": "1618296748"}	["debug_000000"]											
	Bug-229	BUG	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority	java.lang.AssertionError	Get expected JMX for CallVolumeSummary after decay	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority(TestDecayRpcScheduler.java:239), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testPriority/campaign/failures/debug_000000	{"ipc.12.faircallqueue.decay-scheduler.decay-factor": "0.10318100452423096"}	["debug_000000"]											
	Bug-9	BUG	2	org.apache.hadoop.ipc.TestRPC#testDecayRpcSchedulerMetrics	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.DecayRpcScheduler.getDefaultThresholds(DecayRpcScheduler.java:377), org.apache.hadoop.ipc.DecayRpcScheduler.parseThresholds(DecayRpcScheduler.java:346), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:231), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createScheduler(CallQueueManager.java:111), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.setupDecayRpcSchedulerandTestServer(TestRPC.java:1538), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics(TestRPC.java:1423), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testDecayRpcSchedulerMetrics/campaign/failures/debug_000004	{"ipc.0.faircallqueue.priority-levels": "2006542071"}	["debug_000004", "debug_000003"]	org.apache.hadoop.ipc.TestRPC#testProtocolUserPriority	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.DecayRpcScheduler.getDefaultThresholds(DecayRpcScheduler.java:377), org.apache.hadoop.ipc.DecayRpcScheduler.parseThresholds(DecayRpcScheduler.java:346), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:231), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createScheduler(CallQueueManager.java:111), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.setupDecayRpcSchedulerandTestServer(TestRPC.java:1538), org.apache.hadoop.ipc.TestRPC.testProtocolUserPriority(TestRPC.java:1482), org.apache.hadoop.ipc.TestRPC.testProtocolUserPriority$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testProtocolUserPriority/campaign/failures/debug_000002	{"ipc.0.faircallqueue.priority-levels": "1204463548"}	["debug_000002"]
	invalid value	FP	2	org.apache.hadoop.ipc.TestRPC#testDecayRpcSchedulerMetrics	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createScheduler(CallQueueManager.java:111), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.setupDecayRpcSchedulerandTestServer(TestRPC.java:1538), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics(TestRPC.java:1423), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testDecayRpcSchedulerMetrics/campaign/failures/debug_000001	{"ipc.0.faircallqueue.decay-scheduler.decay-factor": "-0.46991807222366333"}	["debug_000001"]	org.apache.hadoop.ipc.TestRPC#testProtocolUserPriority	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createScheduler(CallQueueManager.java:111), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:79), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.setupDecayRpcSchedulerandTestServer(TestRPC.java:1538), org.apache.hadoop.ipc.TestRPC.testProtocolUserPriority(TestRPC.java:1482), org.apache.hadoop.ipc.TestRPC.testProtocolUserPriority$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testProtocolUserPriority/campaign/failures/debug_000001	{"ipc.0.faircallqueue.decay-scheduler.decay-factor": "-0.29293733835220337"}	["debug_000001"]
	Hardcode Assertion	FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesIfMaxAttemptsNotSet	org.mockito.exceptions.verification.TooManyActualInvocations	kMSClientProvider.createKey(    "test3",    <any org.apache.hadoop.crypto.key.KeyProvider.Options>);Wanted 2 times:-> at org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659)But was 19 times:-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesIfMaxAttemptsNotSet/campaign/failures/debug_000001	{"hadoop.security.kms.client.failover.sleep.max.millis": "640", "hadoop.security.kms.client.failover.max.retries": "23596"}	["debug_000001"]											
	Bug-174, Bug-202	BUG	1	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveLruMetadataCacheFs	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveLruMetadataCacheFs/campaign/failures/debug_000001	{"io.file.buffer.size": "2140820856", "file.bytes-per-checksum": "496548494", "file.stream-buffer-size": "2105239037"}	["debug_000001"]											
	Bug-202	BUG	1	org.apache.hadoop.io.TestSequenceFile#testZlibSequenceFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.SequenceFile$Sorter$SortPass.flush(SequenceFile.java:3100), org.apache.hadoop.io.SequenceFile$Sorter$SortPass.run(SequenceFile.java:3051), org.apache.hadoop.io.SequenceFile$Sorter.sortPass(SequenceFile.java:2949), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2897), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2938), org.apache.hadoop.io.TestSequenceFile.sortTest(TestSequenceFile.java:286), org.apache.hadoop.io.TestSequenceFile.compressedSeqFileTest(TestSequenceFile.java:145), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile(TestSequenceFile.java:57), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testZlibSequenceFile/campaign/failures/debug_000000	{"hadoop.security.token.service.use_ip": "true", "file.stream-buffer-size": "29678", "file.bytes-per-checksum": "1170309022"}	["debug_000000"]											
	Bug-207	BUG	1	org.apache.hadoop.ha.TestZKFailoverController#testGracefulFailoverFailBecomingStandby	org.apache.hadoop.ha.ServiceFailedException	Unable to become active. Local node did not get an opportunity to do so from ZooKeeper, or the local node took too long to transition to active.	org.apache.hadoop.ha.ZKFailoverController.doGracefulFailover(ZKFailoverController.java:713), org.apache.hadoop.ha.ZKFailoverController.access$400(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$3.run(ZKFailoverController.java:629), org.apache.hadoop.ha.ZKFailoverController$3.run(ZKFailoverController.java:626), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ha.ZKFailoverController.gracefulFailoverToYou(ZKFailoverController.java:626), org.apache.hadoop.ha.ZKFCRpcServer.gracefulFailover(ZKFCRpcServer.java:94), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverFailBecomingStandby(TestZKFailoverController.java:587), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverFailBecomingStandby$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testGracefulFailoverFailBecomingStandby/campaign/failures/debug_000003	{"ha.failover-controller.graceful-fence.rpc-timeout.ms": "1092752431"}	["debug_000003"]											
	Bug-2, Bug-202	BUG	1	org.apache.hadoop.fs.TestFsShellCopy#testCopyCrc	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.shellRun(TestFsShellCopy.java:81), org.apache.hadoop.fs.TestFsShellCopy.testCopyCrc(TestFsShellCopy.java:98), org.apache.hadoop.fs.TestFsShellCopy.testCopyCrc$$CONFUZZ(TestFsShellCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyCrc/campaign/failures/debug_000001	{"io.file.buffer.size": "1726864352", "file.bytes-per-checksum": "2092986437"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<2> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:312), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000006	{"ipc.15.weighted-cost.lockexclusive": "800", "ipc.15.weighted-cost.lockfree": "2944", "ipc.15.weighted-cost.lockshared": "149"}	["debug_000006"]											
	Bug-208	BUG	2	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryUnknownLength	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength(TestTFileStreams.java:117), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryUnknownLength/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "1601004294", "file.bytes-per-checksum": "2009586446"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:137), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000002	{"tfile.fs.input.buffer.size": "2135632853", "file.bytes-per-checksum": "2015729862"}	["debug_000002"]
	invalid value	FP	1	org.apache.hadoop.ipc.TestAsyncIPC#testCallRetryCount	java.lang.IllegalArgumentException	numLevels must be at least 1	org.apache.hadoop.ipc.CallQueueManager.parseNumLevels(CallQueueManager.java:355), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:78), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:226), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:219), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:200), org.apache.hadoop.ipc.TestAsyncIPC.testCallRetryCount(TestAsyncIPC.java:448), org.apache.hadoop.ipc.TestAsyncIPC.testCallRetryCount$$CONFUZZ(TestAsyncIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestAsyncIPC/testCallRetryCount/campaign/failures/debug_000002	{"ipc.0.scheduler.priority.levels": "0"}	["debug_000002"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestRPC#testClientBackOff	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:callQueueManager.addInternal(<any>, false);-> at org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203)However, there were exactly 2 interactions with this mock:callQueueManager.take();-> at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)callQueueManager.size();-> at org.apache.hadoop.ipc.Server$ConnectionManager.register(Server.java:3800)	org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:113), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000000	{"ipc.5.decay-scheduler.decay-factor": "-0.3749370574951172"}	["debug_000000", "debug_000004", "debug_000002", "debug_000001", "debug_000003"]											
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testTwoDataEntries/campaign/failures/debug_000000	{"file.bytes-per-checksum": "673498998", "tfile.fs.output.buffer.size": "1663818906", "file.stream-buffer-size": "1061107872", "io.file.buffer.size": "2029000572"}	["debug_000000"]											
	Bug-175	BUG	2	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testInputStreamClosedTwice	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.testInputStreamClosedTwice(FSMainOperationsBaseTest.java:1093), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testInputStreamClosedTwice$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testInputStreamClosedTwice/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2015328862", "io.file.buffer.size": "1388778684"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateNewFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.ContractTestUtils.readDataset(ContractTestUtils.java:214), org.apache.hadoop.fs.contract.ContractTestUtils.verifyFileContents(ContractTestUtils.java:240), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateNewFile(AbstractContractCreateTest.java:72), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateNewFile(AbstractContractCreateTest.java:77), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testCreateNewFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateNewFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1506088679", "file.bytes-per-checksum": "2091058333"}	["debug_000001"]
	Bug-202	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureCompressionNotWorking	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking(TestTFileStreams.java:386), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureCompressionNotWorking$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureCompressionNotWorking/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1590220916", "tfile.io.chunk.size": "1874986337", "io.file.buffer.size": "2030157053"}	["debug_000002"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProviderNoRequests	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.getSchedulerWithWeightedTimeCostProvider(TestDecayRpcScheduler.java:390), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProviderNoRequests(TestDecayRpcScheduler.java:374), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProviderNoRequests$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProviderNoRequests/campaign/failures/debug_000000	{"ipc.18.decay-scheduler.decay-factor": "-0.24803674221038818"}	["debug_000000"]											
	Bug-170	BUG	1	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsFileAndDestinationIsDirectory	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.LocalFileSystem.copyFromLocalFile(LocalFileSystem.java:82), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2411), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsFileAndDestinationIsDirectory(AbstractContractCopyFromLocalTest.java:129), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testSourceIsFileAndDestinationIsDirectory$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsFileAndDestinationIsDirectory/campaign/failures/debug_000000	{"io.file.buffer.size": "1598297754", "file.bytes-per-checksum": "1055522361"}	["debug_000000"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseFactor	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor(TestDecayRpcScheduler.java:89), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseFactor/campaign/failures/debug_000001	{"ipc.3.decay-scheduler.decay-factor": "-0.4921913146972656"}	["debug_000001"]											
	Bug-175	BUG	1	org.apache.hadoop.security.alias.TestCredentialProviderFactory#testJksProvider	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.security.alias.KeyStoreProvider.getInputStreamForFile(KeyStoreProvider.java:65), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.locateKeystore(AbstractJavaKeyStoreProvider.java:325), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.<init>(AbstractJavaKeyStoreProvider.java:86), org.apache.hadoop.security.alias.KeyStoreProvider.<init>(KeyStoreProvider.java:49), org.apache.hadoop.security.alias.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:42), org.apache.hadoop.security.alias.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:35), org.apache.hadoop.security.alias.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:68), org.apache.hadoop.security.alias.CredentialProviderFactory.getProviders(CredentialProviderFactory.java:91), org.apache.hadoop.security.alias.TestCredentialProviderFactory.checkPermissionRetention(TestCredentialProviderFactory.java:279), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testJksProvider(TestCredentialProviderFactory.java:223), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testJksProvider$$CONFUZZ(TestCredentialProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredentialProviderFactory/testJksProvider/campaign/failures/debug_000000	{"file.bytes-per-checksum": "2120604259", "hadoop.security.groups.cache.warn.after.ms": "89437953", "hadoop.security.groups.cache.secs": "4671", "io.file.buffer.size": "549151949", "fs.client.resolve.remote.symlinks": "false", "fs.creation.parallel.count": "5616"}	["debug_000000"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:113), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000000	{"ipc.6.faircallqueue.decay-scheduler.decay-factor": "-0.31262874603271484"}	["debug_000000", "debug_000004", "debug_000002", "debug_000001", "debug_000003"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ha.TestZKFailoverController#testCedeActive	java.lang.RuntimeException	ZK Failover Controller failed: Failed to reEstablish connection with ZooKeeper	org.apache.hadoop.ha.ZKFailoverController.mainLoop(ZKFailoverController.java:392), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:253), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testCedeActive/campaign/failures/debug_000001	{"ha.failover-controller.active-standby-elector.zk.op.retries": "0"}	["debug_000001"]											
	Bug-175	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureOpenRandomFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:411), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureOpenRandomFile$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1468015093", "hadoop.security.groups.cache.background.reload": "false", "io.file.buffer.size": "549004246"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:321), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000011	{"ipc.15.weighted-cost.lockfree": "481", "ipc.15.faircallqueue.decay-scheduler.decay-factor": "4.8828125E-4"}	["debug_000011"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<2> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:312), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000007	{"ipc.15.weighted-cost.lockshared": "15", "ipc.15.weighted-cost.lockfree": "513"}	["debug_000007"]											
Flaky test	Bug-209	BUG	1	org.apache.hadoop.fs.TestFileContextResolveAfs#testFileContextResolveAfs	java.io.IOException	Error 1 creating symlink file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/TestFileContextResolveAfs2 to /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/TestFileContextResolveAfs1	org.apache.hadoop.fs.RawLocalFileSystem.createSymlink(RawLocalFileSystem.java:1061), org.apache.hadoop.fs.DelegateToFileSystem.createSymlink(DelegateToFileSystem.java:249), org.apache.hadoop.fs.FilterFs.createSymlink(FilterFs.java:304), org.apache.hadoop.fs.FileContext$21.next(FileContext.java:1575), org.apache.hadoop.fs.FileContext$21.next(FileContext.java:1571), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.createSymlink(FileContext.java:1578), org.apache.hadoop.fs.TestFileContextResolveAfs.testFileContextResolveAfs(TestFileContextResolveAfs.java:61), org.apache.hadoop.fs.TestFileContextResolveAfs.testFileContextResolveAfs$$CONFUZZ(TestFileContextResolveAfs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileContextResolveAfs/testFileContextResolveAfs/campaign/failures/debug_000001	{"fs.defaultFS": "file:///"}	["debug_000001"]											
	Bug-175	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOpenRandomFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:411), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureOpenRandomFile$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1186593955", "file.stream-buffer-size": "1697290423"}	["debug_000000"]											
	Bug-202	BUG	1	org.apache.hadoop.fs.TestFsShellCopy#testDirectCopy	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:312), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.checkDirectCopy(TestFsShellCopy.java:575), org.apache.hadoop.fs.TestFsShellCopy.testDirectCopy(TestFsShellCopy.java:556),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testDirectCopy/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1556661375", "io.file.buffer.size": "145262928", "hadoop.security.dns.log-slow-lookups.threshold.ms": "522600145", "hadoop.security.groups.cache.warn.after.ms": "554088074"}	["debug_000001"]											
	Bug-143	BUG	1	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testListLocatedFileStatus	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testListLocatedFileStatus(TestChRootedFileSystem.java:405), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testListLocatedFileStatus$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testListLocatedFileStatus/campaign/failures/debug_000001	{"fs.viewfs.impl.disable.cache": "true", "fs.viewfs.mounttable.default.name.key": "default"}	["debug_000001"]											
	Bug-7	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryMixedLengths2	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryMixedLengths2/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638", "hadoop.security.groups.negative-cache.secs": "24082", "file.bytes-per-checksum": "2130640638"}	["debug_000001"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testNPEatInitialization	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testNPEatInitialization(TestDecayRpcScheduler.java:279), org.apache.hadoop.ipc.TestDecayRpcScheduler.testNPEatInitialization$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testNPEatInitialization/campaign/failures/debug_000001	{"ipc.14.faircallqueue.decay-scheduler.decay-factor": "-0.32164448499679565"}	["debug_000001"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:113), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000000	{"ipc.7.faircallqueue.decay-scheduler.decay-factor": "-0.36895549297332764"}	["debug_000000", "debug_000004", "debug_000002", "debug_000001", "debug_000003"]											
	Bug-199	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryKnownLength	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryKnownLength(TestTFileStreams.java:106), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testOneEntryKnownLength$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryKnownLength/campaign/failures/debug_000001	{"tfile.fs.input.buffer.size": "1399040000", "io.file.buffer.size": "2141572437", "file.bytes-per-checksum": "1485184941"}	["debug_000001"]											
	Bug-204	BUG	2	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testTwoDataEntries/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2147483527", "tfile.fs.output.buffer.size": "2145979551"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(TestTFileByteArrays.java:271), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2147112593", "file.bytes-per-checksum": "2130640638"}	["debug_000001"]
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestRPC#testClientBackOff	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:callQueueManager.addInternal(<any>, false);-> at org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203)However, there were exactly 2 interactions with this mock:callQueueManager.take();-> at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)callQueueManager.size();-> at org.apache.hadoop.ipc.Server$ConnectionManager.register(Server.java:3800)	org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]											
	Bug-175	BUG	1	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testGetWrappedInputStream	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.testGetWrappedInputStream(FSMainOperationsBaseTest.java:1115), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testGetWrappedInputStream$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testGetWrappedInputStream/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2128984570", "io.file.buffer.size": "85935752", "hadoop.security.dns.log-slow-lookups.threshold.ms": "507", "hadoop.kerberos.min.seconds.before.relogin": "215298568", "hadoop.security.token.service.use_ip": "false"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestRPC#testClientRpcTimeout	java.lang.AssertionError	RPC should not time out.	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout(TestRPC.java:1587), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientRpcTimeout/campaign/failures/debug_000001	{"ipc.0.backoff.enable": "true"}	["debug_000001"]											
	invalid value	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:116), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000000	{"ipc.8.decay-scheduler.decay-factor": "-0.450519323348999"}	["debug_000000", "debug_000004", "debug_000002", "debug_000001", "debug_000003"]											
decayed and removed	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<3> but was:<2>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:325), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000005	{"ipc.15.weighted-cost.lockshared": "995", "ipc.15.faircallqueue.decay-scheduler.decay-factor": "7.271766662597656E-6", "ipc.15.weighted-cost.lockexclusive": "9546"}	["debug_000005"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestIPC#testRTEOnServerWriteResponse	java.lang.AssertionError	Exception should contain substring 'Injected fault':org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): Null protocol not authorized at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612) at org.apache.hadoop.ipc.Client.call(Client.java:1558) at org.apache.hadoop.ipc.Client.call(Client.java:1477) at org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:177) at org.apache.hadoop.ipc.TestIPC.doErrorTest(TestIPC.java:528) at org.apache.hadoop.ipc.TestIPC.testRTEOnServerWriteResponse(TestIPC.java:598) at org.apache.hadoop.ipc.TestIPC.testRTEOnServerWriteResponse$$CONFUZZ(TestIPC.java) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65) at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101) at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208) at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestIPC.assertExceptionContains(TestIPC.java:644), org.apache.hadoop.ipc.TestIPC.doErrorTest(TestIPC.java:531), org.apache.hadoop.ipc.TestIPC.testRTEOnServerWriteResponse(TestIPC.java:598), org.apache.hadoop.ipc.TestIPC.testRTEOnServerWriteResponse$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testRTEOnServerWriteResponse/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestIPCServerResponder#testResponseBuffer	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.junit.Assert.assertFalse(Assert.java:75), org.apache.hadoop.ipc.TestIPCServerResponder.checkServerResponder(TestIPCServerResponder.java:174), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer(TestIPCServerResponder.java:142), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer$$CONFUZZ(TestIPCServerResponder.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPCServerResponder/testResponseBuffer/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]											
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.groups.cache.secs": "629", "hadoop.service.shutdown.timeout": "430180552m", "file.stream-buffer-size": "270", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "519307129", "fs.creation.parallel.count": "27446", "file.bytes-per-checksum": "2106068444", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.enabled": "false", "fs.local.block.size": "641765607", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "1008362913", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "363", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "1289109177"}	["debug_000001"]											
	Bug-173	BUG	1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000001	{"io.compression.codec.snappy.buffersize": "999830480", "io.file.buffer.size": "1790167039"}	["debug_000001"]											
	Bug-86	BUG	1	org.apache.hadoop.http.TestGlobalFilter#testServletFilter	java.lang.IllegalStateException	Insufficient configured threads: required=896 < max=797 for QueuedThreadPool[qtp1217507042]@4891aee2{STARTED,8<=8<=797,i=8,r=-1,q=0}[ReservedThreadExecutor@38617f1c{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestGlobalFilter.testServletFilter(TestGlobalFilter.java:112), org.apache.hadoop.http.TestGlobalFilter.testServletFilter$$CONFUZZ(TestGlobalFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestGlobalFilter/testServletFilter/campaign/failures/debug_000000	{"hadoop.http.selector.count": "124", "hadoop.http.acceptor.count": "770", "hadoop.http.max.threads": "797"}	["debug_000000"]											
		Non-Reproducible	1	org.apache.hadoop.ha.TestZKFailoverController#testCedeActive	java.lang.AssertionError	Should take ~3 seconds to rejoin. Only took 2566ms before rejoining.	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ha.TestZKFailoverController.testCedeActive(TestZKFailoverController.java:475), org.apache.hadoop.ha.TestZKFailoverController.testCedeActive$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testCedeActive/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "8894"}	["debug_000000"]											
Tony: i cannot repro this		Non-Reproducible	1	org.apache.hadoop.ipc.TestIPC#testConnectionIdleTimeouts	java.lang.AssertionError	expected:<4> but was:<7>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestIPC.testConnectionIdleTimeouts(TestIPC.java:1085), org.apache.hadoop.ipc.TestIPC.testConnectionIdleTimeouts$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testConnectionIdleTimeouts/campaign/failures/debug_000000	{"ipc.server.handler.queue.size": "2030730463"}	["debug_000000"]											
	Bug-212	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "1854076498", "file.bytes-per-checksum": "1971251642"}	["debug_000000"]											
	Bug-201	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:125), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2130640638", "tfile.io.chunk.size": "2147483519"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<3> but was:<2>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:325), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000004	{"ipc.15.decay-scheduler.decay-factor": "4.589557647705078E-6", "ipc.15.weighted-cost.lockexclusive": "4805", "ipc.15.weighted-cost.lockshared": "507"}	["debug_000004"]											
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000001	{"hadoop.service.shutdown.timeout": "5807654s", "tfile.fs.output.buffer.size": "2130640638", "file.bytes-per-checksum": "2130640638"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<1> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:322), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000005	{"ipc.15.faircallqueue.decay-scheduler.decay-factor": "3.4117698669433594E-4", "ipc.15.weighted-cost.lockexclusive": "140"}	["debug_000005"]											
		Non-Reproducible	1	org.apache.hadoop.ha.TestZKFailoverController#testFormatOneClusterLeavesOtherClustersAlone	java.lang.AssertionError	expected:<3> but was:<6>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone(TestZKFailoverController.java:159), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatOneClusterLeavesOtherClustersAlone/campaign/failures/debug_000001	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "14044", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "375", "ha.failover-controller.active-standby-elector.zk.op.retries": "793", "hadoop.security.authentication": "kerberos", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.min.seconds.before.relogin": "23564", "ha.zookeeper.session-timeout.ms": "39", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "860654493"}	["debug_000001"]											
	Bug-171, Bug-189	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriterNotClosed	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriterNotClosed(TestTFileByteArrays.java:256), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureWriterNotClosed$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriterNotClosed/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "196", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "202s", "file.stream-buffer-size": "1847151721", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "112", "fs.creation.parallel.count": "553605745", "file.bytes-per-checksum": "226", "hadoop.security.dns.log-slow-lookups.threshold.ms": "1184286789", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "31592", "fs.local.block.size": "24251", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "1112190004", "hadoop.security.token.service.use_ip": "false", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "653"}	["debug_000000"]											
	Bug-175	BUG	1	org.apache.hadoop.util.TestGenericOptionsParser#testTokenCacheOption	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.security.Credentials.readTokenStorageFile(Credentials.java:222), org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:353), org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:573), org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:175), org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:157), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption(TestGenericOptionsParser.java:285), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption$$CONFUZZ(TestGenericOptionsParser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestGenericOptionsParser/testTokenCacheOption/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1971344140", "io.file.buffer.size": "992787947", "hadoop.security.groups.cache.background.reload.threads": "13930"}	["debug_000001"]											
	Bug-175	BUG	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateNewFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.ContractTestUtils.readDataset(ContractTestUtils.java:214), org.apache.hadoop.fs.contract.ContractTestUtils.verifyFileContents(ContractTestUtils.java:240), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateNewFile(AbstractContractCreateTest.java:72), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateNewFile(AbstractContractCreateTest.java:77), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testCreateNewFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateNewFile/campaign/failures/debug_000001	{"fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "file.bytes-per-checksum": "2039658509", "io.file.buffer.size": "1735926313", "hadoop.security.groups.negative-cache.secs": "4263"}	["debug_000001"]											
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureFileWriteNotAt0Position	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position(TestTFileByteArrays.java:561), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureFileWriteNotAt0Position$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000001	{"io.file.buffer.size": "1604993424", "file.bytes-per-checksum": "1087901820", "fs.creation.parallel.count": "14037", "tfile.fs.output.buffer.size": "1958953913"}	["debug_000001"]											
	Bug-213	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000000	{"file.stream-buffer-size": "1867923042", "tfile.fs.input.buffer.size": "1971483699", "tfile.fs.output.buffer.size": "1630653394"}	["debug_000000"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestIPC#testInitialCallRetryCount	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.junit.Assert.assertFalse(Assert.java:75), org.apache.hadoop.ipc.TestIPC.testInitialCallRetryCount(TestIPC.java:1382), org.apache.hadoop.ipc.TestIPC.testInitialCallRetryCount$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testInitialCallRetryCount/campaign/failures/debug_000000	{"ipc.maximum.response.length": "5"}	["debug_000000"]											
	Bug-212	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000002	{"file.bytes-per-checksum": "690788304", "file.stream-buffer-size": "1584439485", "tfile.fs.output.buffer.size": "1532985315"}	["debug_000002"]											
	Bug-189	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureWriterNotClosed	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriterNotClosed(TestTFileByteArrays.java:256), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureWriterNotClosed$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureWriterNotClosed/campaign/failures/debug_000000	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "627", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "896088401", "hadoop.security.authentication": "kerberos", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "234005s", "file.stream-buffer-size": "30745", "hadoop.security.groups.cache.background.reload.threads": "27314", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "1914393768", "hadoop.kerberos.min.seconds.before.relogin": "151476720", "hadoop.security.groups.negative-cache.secs": "1634941775", "fs.creation.parallel.count": "22112", "file.bytes-per-checksum": "1509340455", "hadoop.security.groups.cache.warn.after.ms": "1760178891"}	["debug_000000"]											
	Bug-171, Bug-189, Bug-212	BUG	1	org.apache.hadoop.fs.TestChecksumFileSystem#testTruncatedChecksum	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileSystemTestHelper.readFile(FileSystemTestHelper.java:203), org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum(TestChecksumFileSystem.java:158), org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum$$CONFUZZ(TestChecksumFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testTruncatedChecksum/campaign/failures/debug_000001	{"file.bytes-per-checksum": "199442032", "file.stream-buffer-size": "840237319", "io.file.buffer.size": "1357361240"}	["debug_000001"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.ipc.TestIPCServerResponder#testResponseBuffer	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.junit.Assert.assertFalse(Assert.java:75), org.apache.hadoop.ipc.TestIPCServerResponder.checkServerResponder(TestIPCServerResponder.java:174), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer(TestIPCServerResponder.java:142), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer$$CONFUZZ(TestIPCServerResponder.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPCServerResponder/testResponseBuffer/campaign/failures/debug_000000	{"ipc.maximum.response.length": "241"}	["debug_000000"]											
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:108), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testNoDataEntry$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testNoDataEntry/campaign/failures/debug_000001	{"hadoop.security.groups.cache.secs": "1692468687", "file.stream-buffer-size": "1814434393", "io.file.buffer.size": "1912783984", "tfile.fs.output.buffer.size": "1095186718", "file.bytes-per-checksum": "157740965"}	["debug_000001"]											
		Non-Reproducible	1	org.apache.hadoop.fs.TestChecksumFileSystem#testCorruptedChecksum	java.lang.AssertionError	got checksum error	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertNotNull(Assert.java:713), org.apache.hadoop.fs.TestChecksumFileSystem.testCorruptedChecksum(TestChecksumFileSystem.java:232), org.apache.hadoop.fs.TestChecksumFileSystem.testCorruptedChecksum$$CONFUZZ(TestChecksumFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testCorruptedChecksum/campaign/failures/debug_000002	{"io.file.buffer.size": "1285405361", "file.bytes-per-checksum": "1561281418"}	["debug_000002"]											
	Bug-175	BUG	2	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "1237697863", "file.bytes-per-checksum": "1587185514"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:387), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureOpenEmptyFile$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "1524193698", "file.bytes-per-checksum": "1923704066"}	["debug_000001"]
	Bug-212	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:387), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000002	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "822", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "22371", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.service.shutdown.timeout": "60s", "file.stream-buffer-size": "2892", "hadoop.security.groups.cache.background.reload.threads": "4561", "fs.local.block.size": "1153269210", "hadoop.security.groups.cache.background.reload": "false", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "14331", "hadoop.security.groups.negative-cache.secs": "890", "tfile.fs.output.buffer.size": "27781", "fs.creation.parallel.count": "12615", "file.bytes-per-checksum": "2093600406", "hadoop.security.groups.cache.warn.after.ms": "290149515"}	["debug_000002"]											
	Bug-175	BUG	1	org.apache.hadoop.fs.TestHarFileSystemBasics#testMakeQualifiedPath	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1173), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testMakeQualifiedPath/campaign/failures/debug_000001	{"hadoop.security.groups.cache.warn.after.ms": "26", "hadoop.security.dns.log-slow-lookups.threshold.ms": "550", "io.file.buffer.size": "768647010", "fs.local.block.size": "16", "hadoop.security.groups.cache.secs": "13252", "file.bytes-per-checksum": "1994476254"}	["debug_000001"]											
	Bug-212	BUG	1	org.apache.hadoop.io.file.tfile.TestTFile#testUnsortedTFileFeatures	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:346), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures$$CONFUZZ(TestTFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testUnsortedTFileFeatures/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1133421309", "hadoop.kerberos.keytab.login.autorenewal.enabled": "true"}	["debug_000000"]											
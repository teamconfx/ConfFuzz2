[
    {
        "status": "BUG",
        "bugId": [
            "Bug-11"
        ],
        "testClass": "org.apache.hadoop.yarn.webapp.TestWebApp",
        "testMethod": "testDefaultRoutes",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:457)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes(TestWebApp.java:221)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes$$CONFUZZ(TestWebApp.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.http.policy": "HTTPS_ONLY",
            "hadoop.http.selector.count": "1797431237"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC",
        "testMethod": "testHadoopProtoRPCTimeout",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Error, exception is not: java.net.SocketTimeoutException expected:<[java.net.SocketTimeout]Exception> but was:<[org.apache.hadoop.security.AccessControl]Exception>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testRPCTimeout(TestContainerResourceIncreaseRPC.java:125)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout(TestContainerResourceIncreaseRPC.java:82)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerResourceIncreaseRPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.util.resource.TestResourceUtils",
        "testMethod": "testGetResourceTypesConfigs",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<2> but was:<3>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.yarn.util.resource.TestResourceUtils.testGetResourceTypesConfigs(TestResourceUtils.java:186)",
            "org.apache.hadoop.yarn.util.resource.TestResourceUtils.testGetResourceTypesConfigs$$CONFUZZ(TestResourceUtils.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resource-types": "resource1"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-204"
        ],
        "testClass": "org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat",
        "testMethod": "testReadAcontainerLogs1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Requested array size exceeds VM limit",
        "stackTrace": [
            "org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146)",
            "org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125)",
            "org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431)",
            "org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642)",
            "org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533)",
            "org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.writeVersion(AggregatedLogFormat.java:499)",
            "org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.initialize(AggregatedLogFormat.java:490)",
            "org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testReadAcontainerLog(TestAggregatedLogFormat.java:237)",
            "org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testReadAcontainerLogs1(TestAggregatedLogFormat.java:203)",
            "org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testReadAcontainerLogs1$$CONFUZZ(TestAggregatedLogFormat.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "tfile.fs.output.buffer.size": "2147483646"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPostEntities",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:140)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities$$CONFUZZ(TestTimelineClientForATS1_5.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)", 
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)", 
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",  
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",    
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)", 
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",  
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.entity-group-fs-store.with-user-dir": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-8"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPutDomain",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.client.internal-attempt-dir-cache-size": "1010569524",
            "file.stream-buffer-size": "1973613242"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPutDomain",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPutDomain(TestTimelineClientForATS1_5.java:203)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPutDomain(TestTimelineClientForATS1_5.java:176)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPutDomain$$CONFUZZ(TestTimelineClientForATS1_5.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.entity-group-fs-store.with-user-dir": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-7"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPutDomain",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.client.internal-attempt-dir-cache-size": "760520203",
            "io.file.buffer.size": "2130640638"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-118"
        ],
        "testClass": "org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager",
        "testMethod": "testAddReplaceRemoveLabelsOnNodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.yarn.nodelabels.NodeLabelTestBase.assertMapEquals(NodeLabelTestBase.java:38)",
            "org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager.testAddReplaceRemoveLabelsOnNodes(TestCommonNodeLabelsManager.java:230)",
            "org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager.testAddReplaceRemoveLabelsOnNodes$$CONFUZZ(TestCommonNodeLabelsManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.node-labels.configuration-type": "delegated-centralized"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-175"
        ],
        "testClass": "org.apache.hadoop.yarn.webapp.util.TestWebAppUtils",
        "testMethod": "testGetPassword",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173)",
            "org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)",
            "org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)",
            "org.apache.hadoop.security.alias.KeyStoreProvider.getInputStreamForFile(KeyStoreProvider.java:65)",
            "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.locateKeystore(AbstractJavaKeyStoreProvider.java:325)",
            "org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.<init>(AbstractJavaKeyStoreProvider.java:86)",
            "org.apache.hadoop.security.alias.KeyStoreProvider.<init>(KeyStoreProvider.java:49)",
            "org.apache.hadoop.security.alias.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:42)",
            "org.apache.hadoop.security.alias.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:35)",
            "org.apache.hadoop.security.alias.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:68)",
            "org.apache.hadoop.security.alias.CredentialProviderFactory.getProviders(CredentialProviderFactory.java:91)",
            "org.apache.hadoop.conf.Configuration.getPasswordFromCredentialProviders(Configuration.java:2506)",
            "org.apache.hadoop.conf.Configuration.getPassword(Configuration.java:2444)",
            "org.apache.hadoop.yarn.webapp.util.WebAppUtils.getPassword(WebAppUtils.java:489)",
            "org.apache.hadoop.yarn.webapp.util.TestWebAppUtils.testGetPassword(TestWebAppUtils.java:99)",
            "org.apache.hadoop.yarn.webapp.util.TestWebAppUtils.testGetPassword$$CONFUZZ(TestWebAppUtils.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2029551709",
            "io.file.buffer.size": "1327544759"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.TestContainerLaunchRPC",
        "testMethod": "testHadoopProtoRPCTimeout",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Error, exception is not: java.net.SocketTimeoutException expected:<[java.net.SocketTimeout]Exception> but was:<[org.apache.hadoop.security.AccessControl]Exception>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.yarn.TestContainerLaunchRPC.testRPCTimeout(TestContainerLaunchRPC.java:139)",
            "org.apache.hadoop.yarn.TestContainerLaunchRPC.testHadoopProtoRPCTimeout(TestContainerLaunchRPC.java:90)",
            "org.apache.hadoop.yarn.TestContainerLaunchRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerLaunchRPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.client.TestClientRMProxy",
        "testMethod": "testProxyUserCorrectUGI",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertNotNull(Assert.java:713)",
            "org.junit.Assert.assertNotNull(Assert.java:723)",
            "org.apache.hadoop.yarn.client.TestClientRMProxy.assertUGI(TestClientRMProxy.java:164)",
            "org.apache.hadoop.yarn.client.TestClientRMProxy.testProxyUserCorrectUGI(TestClientRMProxy.java:158)",
            "org.apache.hadoop.yarn.client.TestClientRMProxy.testProxyUserCorrectUGI$$CONFUZZ(TestClientRMProxy.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.client.failover-proxy-provider": "org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPostEntitiesToKeepUnderUserDir",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Exception is not expected. java.lang.IllegalArgumentException: Non-positive period.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:169)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntitiesToKeepUnderUserDir(TestTimelineClientForATS1_5.java:109)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntitiesToKeepUnderUserDir$$CONFUZZ(TestTimelineClientForATS1_5.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.client.fd-clean-interval-secs": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.webapp.TestWebApp",
        "testMethod": "testYARNWebAppContext",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<404> but was:<431>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext(TestWebApp.java:333)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext$$CONFUZZ(TestWebApp.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "97"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-200",
            "Bug-7"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPostEntities",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createSummaryFDAndWrite(FileSystemTimelineWriter.java:879)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummmaryEntityLogs(FileSystemTimelineWriter.java:863)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummaryEntityLogs(FileSystemTimelineWriter.java:842)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:229)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1474707349",
            "file.bytes-per-checksum": "1470175729"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-86"
        ],
        "testClass": "org.apache.hadoop.yarn.webapp.TestWebApp",
        "testMethod": "testYARNWebAppContext",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=0 < max=0 for QueuedThreadPool[qtp1741095319]@67c70197{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.QueuedThreadPool.setMaxThreads(QueuedThreadPool.java:364)",
            "org.apache.hadoop.http.HttpServer2.initializeWebServer(HttpServer2.java:703)",
            "org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:687)",
            "org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext(TestWebApp.java:325)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext$$CONFUZZ(TestWebApp.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-2"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPostEntities",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createSummaryFDAndWrite(FileSystemTimelineWriter.java:879)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummmaryEntityLogs(FileSystemTimelineWriter.java:863)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummaryEntityLogs(FileSystemTimelineWriter.java:842)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:229)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:416)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:151)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.client.internal-attempt-dir-cache-size": "1552703431",
            "file.bytes-per-checksum": "193025984"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC",
        "testMethod": "testHadoopProtoRPCTimeout",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Error, exception is not: java.net.SocketTimeoutException expected:<[java.net.SocketTimeout]Exception> but was:<[org.apache.hadoop.security.authorize.Authorization]Exception>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testRPCTimeout(TestContainerResourceIncreaseRPC.java:125)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout(TestContainerResourceIncreaseRPC.java:82)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerResourceIncreaseRPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authorization": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-2"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPostEntities",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createEntityFDandWrite(FileSystemTimelineWriter.java:817)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeEntityLogs(FileSystemTimelineWriter.java:795)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeEntityLogs(FileSystemTimelineWriter.java:767)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:237)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:416)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:151)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "689862716"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-11",
            "Bug-10"
        ],
        "testClass": "org.apache.hadoop.yarn.webapp.TestWebApp",
        "testMethod": "testYARNWebAppContext",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext(TestWebApp.java:325)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext$$CONFUZZ(TestWebApp.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.http.policy": "HTTPS_ONLY",
            "hadoop.http.selector.count": "1460953568",
            "hadoop.http.acceptor.count": "634100972"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-200",
            "Bug-7"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPutDomain",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.timeline-service.client.internal-attempt-dir-cache-size": "1874873744",
            "io.file.buffer.size": "1801117294",
            "file.bytes-per-checksum": "130094302"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-200"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPutDomainToKeepUnderUserDir",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1144894387",
            "yarn.timeline-service.client.internal-attempt-dir-cache-size": "752055985"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC",
        "testMethod": "testHadoopProtoRPCTimeout",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Error, exception is not: java.net.SocketTimeoutException expected:<java.[net.SocketTimeout]Exception> but was:<java.[io.EOF]Exception>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testRPCTimeout(TestContainerResourceIncreaseRPC.java:125)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout(TestContainerResourceIncreaseRPC.java:82)",
            "org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerResourceIncreaseRPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "183"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-11",
            "Bug-10"
        ],
        "testClass": "org.apache.hadoop.yarn.webapp.TestWebApp",
        "testMethod": "testCreateWithNonZeroPort",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461)",
            "org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:457)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testCreateWithNonZeroPort(TestWebApp.java:184)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testCreateWithNonZeroPort$$CONFUZZ(TestWebApp.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "1595403199",
            "hadoop.http.acceptor.count": "663921885"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-2"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPostEntities",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createSummaryFDAndWrite(FileSystemTimelineWriter.java:879)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummmaryEntityLogs(FileSystemTimelineWriter.java:863)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummaryEntityLogs(FileSystemTimelineWriter.java:842)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:229)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:416)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:151)",
            "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.http.policy": "HTTPS_ONLY",
            "hadoop.user.group.static.mapping.overrides": "dr.who=;",
            "file.stream-buffer-size": "2017561428",
            "file.bytes-per-checksum": "1660781381",
            "fs.client.resolve.remote.symlinks": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-226"
        ],
        "testClass": "org.apache.hadoop.yarn.util.TestFSDownload",
        "testMethod": "testDownload",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "2082207443",
            "io.file.buffer.size": "1166572912"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-8",
            "Bug-7"
        ],
        "testClass": "org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5",
        "testMethod": "testPutDomainToKeepUnderUserDir",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291)",
            "org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255)",
            "org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "1584506966",
            "yarn.timeline-service.client.internal-attempt-dir-cache-size": "1240621380",
            "io.file.buffer.size": "1454086926"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.yarn.webapp.TestWebApp",
        "testMethod": "testDefaultRoutes",
        "failure": "java.net.SocketException",
        "errorMessage": "Unexpected end of file from server",
        "stackTrace": [
            "java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:899)",
            "java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722)",
            "java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:896)",
            "java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1615)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1520)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.getContent(TestWebApp.java:392)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes(TestWebApp.java:224)",
            "org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes$$CONFUZZ(TestWebApp.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "16039",
            "yarn.http.policy": "HTTPS_ONLY"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-208"
        ],
        "testClass": "org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController",
        "testMethod": "testFetchApplictionLogsHar",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64)",
            "org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71)",
            "org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92)",
            "org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196)",
            "org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.readAggregatedLogs(LogAggregationIndexedFileController.java:587)",
            "org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController.testFetchApplictionLogsHar(TestLogAggregationIndexedFileController.java:425)",
            "org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController.testFetchApplictionLogsHar$$CONFUZZ(TestLogAggregationIndexedFileController.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "indexedFile.fs.input.buffer.size": "1666091541",
            "file.bytes-per-checksum": "1536933200"
        }
    }
]

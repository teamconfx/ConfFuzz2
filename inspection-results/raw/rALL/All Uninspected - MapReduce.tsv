note	bugId	status	times	testName	failure	failureMessage	stackTrace	reproStatus	replayedFailure	replayedErrorMessage	replayedStackTrace	replayedFile	minConfig	debugFiles											
	Bug-172	BUG	1	org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131), org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68), org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381), org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402), org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000003	{"io.file.buffer.size": "2147483520"}	["debug_000003"]											
	Bug-151	BUG	1	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.AssertionError	Commit successful after retry: wrong behavior for version 1.	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:521), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000001	{"mapreduce.fileoutputcommitter.cleanup.skipped": "true"}	["debug_000001"]											
	Bug-2	BUG	2	org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV2	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377), org.apache.hadoop.mapred.FileOutputCommitter.commitJob(FileOutputCommitter.java:136), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:346), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000002	{"io.file.buffer.size": "2103489078", "file.bytes-per-checksum": "703740007"}	["debug_000002"]	org.apache.hadoop.mapreduce.split.TestJobSplitWriter#testMaxBlockLocationsOldSplits	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.mapreduce.split.JobSplitWriter.writeJobSplitMetaInfo(JobSplitWriter.java:189), org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:95), org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:74), org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.split.TestJobSplitWriter/testMaxBlockLocationsOldSplits/campaign/failures/debug_000000	{"io.file.buffer.size": "1959058805", "file.bytes-per-checksum": "1189055308"}	["debug_000000"]
	Hardcode Assertion	FP	1	org.apache.hadoop.mapreduce.TestJobResourceUploader#testErasureCodingDefault	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:distributedFileSystem.setErasureCodingPolicy(    /,    "replication");-> at org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingSetting(TestJobResourceUploader.java:447)However, there were exactly 3 interactions with this mock:distributedFileSystem.getUri();-> at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:163)distributedFileSystem.exists(/test);-> at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:164)distributedFileSystem.makeQualified(/test);-> at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:170)	org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingSetting(TestJobResourceUploader.java:447), org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingDefault(TestJobResourceUploader.java:375), org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingDefault$$CONFUZZ(TestJobResourceUploader.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testErasureCodingDefault/campaign/failures/debug_000000	{"yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled": "true"}	["debug_000000"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testMemoryMerge	java.lang.AssertionError	Should be a memory merge	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testMemoryMerge(TestMergeManager.java:99), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testMemoryMerge$$CONFUZZ(TestMergeManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testMemoryMerge/campaign/failures/debug_000000	{"mapreduce.reduce.merge.memtomem.enabled": "true", "mapreduce.reduce.merge.memtomem.threshold": "1", "mapreduce.task.io.sort.factor": "767"}	["debug_000000"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testMemoryMerge	java.lang.AssertionError	Should be a memory merge	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testMemoryMerge(TestMergeManager.java:99), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testMemoryMerge$$CONFUZZ(TestMergeManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testMemoryMerge/campaign/failures/debug_000000	{"mapreduce.reduce.merge.memtomem.enabled": "true", "fs.creation.parallel.count": "27705", "mapreduce.reduce.merge.memtomem.threshold": "1"}	["debug_000000"]											
	Bug-232	BUG	1	org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache#testSharedCacheArchivesAndLibjarsEnabled	java.io.FileNotFoundException	File file:/tmp/first-input-file does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.mapreduce.JobResourceUploader.getFileStatus(JobResourceUploader.java:647), org.apache.hadoop.mapreduce.JobResourceUploader.explorePath(JobResourceUploader.java:629), org.apache.hadoop.mapreduce.JobResourceUploader.checkLocalizationLimits(JobResourceUploader.java:511), org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:198), org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135), org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache.uploadFilesToRemoteFS(TestJobResourceUploaderWithSharedCache.java:299), org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache.testSharedCacheArchivesAndLibjarsEnabled(TestJobResourceUploaderWithSharedCache.java:204), org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache.testSharedCacheArchivesAndLibjarsEnabled$$CONFUZZ(TestJobResourceUploaderWithSharedCache.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache/testSharedCacheArchivesAndLibjarsEnabled/campaign/failures/debug_000000	{"mapreduce.job.cache.limit.max-resources-mb": "36607"}	["debug_000000"]											
	Bug-172	BUG	1	org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58), org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000005	{"io.file.buffer.size": "1987215562", "mapreduce.output.fileoutputformat.compress": "true", "file.bytes-per-checksum": "1952426254"}	["debug_000005"]											
	Bug-86	BUG	1	org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerUriSubstitution	java.lang.IllegalStateException	Insufficient configured threads: required=129 < max=100 for QueuedThreadPool[qtp1560388331]@5d01a2eb{STARTED,8<=8<=100,i=8,r=-1,q=0}[ReservedThreadExecutor@5a45c218{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerUriSubstitution/campaign/failures/debug_000000	{"hadoop.http.max.threads": "100", "hadoop.http.acceptor.count": "127"}	["debug_000000"]											
	invalid value	FP	1	org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC#testMaxBlockLocationsOldSplitsWithErasureCoding	org.apache.hadoop.HadoopIllegalArgumentException	Invalid values: dfs.bytes-per-checksum (=19492) must divide block size (=10485760).	org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223), org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250), org.apache.hadoop.hdfs.DFSStripedOutputStream.<init>(DFSStripedOutputStream.java:293), org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:315), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170), org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556), org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553), org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81), org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567), org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902), org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.setup(TestJobSplitWriterWithEC.java:81), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC/testMaxBlockLocationsOldSplitsWithErasureCoding/campaign/failures/debug_000001	{"dfs.bytes-per-checksum": "19492"}	["debug_000001"]											
	invalid value	FP	1	org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testZeroShuffleMemoryLimitPercent	java.lang.RuntimeException	Invalid configuration: maxSingleShuffleLimit should be less than mergeThreshold maxSingleShuffleLimit: 0mergeThreshold: 0	org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:215), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent(TestMergeManager.java:320), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent$$CONFUZZ(TestMergeManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testZeroShuffleMemoryLimitPercent/campaign/failures/debug_000002	{"mapreduce.reduce.shuffle.input.buffer.percent": "0.0"}	["debug_000002"]											
	Bug-202	BUG	1	org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryUpgradeV1V2	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377), org.apache.hadoop.mapred.FileOutputCommitter.commitJob(FileOutputCommitter.java:136), org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:154), org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:171), org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testRecoveryUpgradeV1V2/campaign/failures/debug_000005	{"file.bytes-per-checksum": "573644353", "io.file.buffer.size": "629810338", "file.stream-buffer-size": "1750545930"}	["debug_000005"]											
	invalid value	FP	2	org.apache.hadoop.mapreduce.task.reduce.TestMerger#testInMemoryAndOnDiskMerger	java.lang.IllegalArgumentException	Invalid value for mapreduce.reduce.shuffle.memory.limit.percent: -0.23954195	org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:187), org.apache.hadoop.mapreduce.task.reduce.TestMerger.testInMemoryAndOnDiskMerger(TestMerger.java:126), org.apache.hadoop.mapreduce.task.reduce.TestMerger.testInMemoryAndOnDiskMerger$$CONFUZZ(TestMerger.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMerger/testInMemoryAndOnDiskMerger/campaign/failures/debug_000000	{"mapreduce.reduce.shuffle.memory.limit.percent": "-0.2395419478416443"}	["debug_000000"]	org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testOnDiskMerger	java.lang.IllegalArgumentException	Invalid value for mapreduce.reduce.shuffle.memory.limit.percent: -0.11357427	org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:187), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testOnDiskMerger(TestMergeManager.java:228), org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testOnDiskMerger$$CONFUZZ(TestMergeManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testOnDiskMerger/campaign/failures/debug_000001	{"mapreduce.reduce.shuffle.memory.limit.percent": "-0.11357426643371582"}	["debug_000001"]
	invalid value	FP	1	org.apache.hadoop.mapred.TestMapTask#testShufflePermissions	java.lang.RuntimeException	class org.apache.hadoop.util.MergeSort not org.apache.hadoop.util.IndexedSorter	org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2784), org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:995), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions(TestMapTask.java:74), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions$$CONFUZZ(TestMapTask.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestMapTask/testShufflePermissions/campaign/failures/debug_000002	{"map.sort.class": "org.apache.hadoop.util.MergeSort"}	["debug_000002"]											
	invalid value	FP	1	org.apache.hadoop.mapred.TestMapTask#testShufflePermissions	java.io.IOException	Invalid "mapreduce.task.io.sort.mb": 1398949790	org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:992), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions(TestMapTask.java:74), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions$$CONFUZZ(TestMapTask.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestMapTask/testShufflePermissions/campaign/failures/debug_000001	{"mapreduce.task.io.sort.mb": "1398949790"}	["debug_000001"]											
	Bug-2	BUG	1	org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV2	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377), org.apache.hadoop.mapred.FileOutputCommitter.commitJob(FileOutputCommitter.java:136), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:302), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274), org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV2/campaign/failures/debug_000002	{"file.stream-buffer-size": "2130640638", "file.bytes-per-checksum": "127941218", "io.file.buffer.size": "1995501885"}	["debug_000002"]											
	Bug-173	BUG	2	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2055), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:447), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:412), org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getReaders(MapFileOutputFormat.java:108), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:566), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000000	{"io.file.buffer.size": "1914934350"}	["debug_000000"]	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2067), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:447), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:412), org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getReaders(MapFileOutputFormat.java:108), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:566), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000001	{"io.file.buffer.size": "1313336732"}	["debug_000001"]
	invalid value	FP	1	org.apache.hadoop.mapred.TestMapTask#testShufflePermissions	java.io.IOException	Invalid "mapreduce.map.sort.spill.percent": -0.049647927	org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:988), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions(TestMapTask.java:74), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions$$CONFUZZ(TestMapTask.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestMapTask/testShufflePermissions/campaign/failures/debug_000000	{"mapreduce.map.sort.spill.percent": "-0.04964792728424072"}	["debug_000000"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.mapred.TestLineRecordReader#testRecordSpanningMultipleSplits	org.junit.ComparisonFailure	expected:<[Use with small split] size,> but was:<[] size,>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.mapred.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:256), org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:269), org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testRecordSpanningMultipleSplits/campaign/failures/debug_000001	{"mapreduce.input.linerecordreader.line.maxlength": "10"}	["debug_000001"]											
	Bug-228	BUG	1	org.apache.hadoop.mapred.TestMapTask#testShufflePermissions	java.lang.IllegalArgumentException	capacity < 0: (-666409632 < 0)	java.base/java.nio.Buffer.createCapacityException(Buffer.java:256), java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:347), org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:51), org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1904), org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1528), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions(TestMapTask.java:75), org.apache.hadoop.mapred.TestMapTask.testShufflePermissions$$CONFUZZ(TestMapTask.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestMapTask/testShufflePermissions/campaign/failures/debug_000003	{"mapreduce.job.reduces": "509103844"}	["debug_000003"]											
	invalid value	FP	1	org.apache.hadoop.mapreduce.task.reduce.TestMerger#testEncryptedMerger	java.lang.RuntimeException	Invalid configuration: maxSingleShuffleLimit should be less than mergeThreshold maxSingleShuffleLimit: 1260780416mergeThreshold: 722861568	org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:215), org.apache.hadoop.mapreduce.task.reduce.TestMerger.testInMemoryAndOnDiskMerger(TestMerger.java:126), org.apache.hadoop.mapreduce.task.reduce.TestMerger.testEncryptedMerger(TestMerger.java:111), org.apache.hadoop.mapreduce.task.reduce.TestMerger.testEncryptedMerger$$CONFUZZ(TestMerger.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMerger/testEncryptedMerger/campaign/failures/debug_000002	{"mapreduce.reduce.shuffle.memory.limit.percent": "0.4385279417037964", "mapreduce.reduce.shuffle.merge.percent": "0.2514275908470154"}	["debug_000002"]											
	Bug-173	BUG	1	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testProgressDuringMerge	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131), org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testProgressDuringMerge/campaign/failures/debug_000002	{"io.file.buffer.size": "1619820365", "file.stream-buffer-size": "869676245"}	["debug_000002"]											
	Bug-202	BUG	1	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV1	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:440), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:367), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV1/campaign/failures/debug_000007	{"file.bytes-per-checksum": "1469970389", "io.file.buffer.size": "1069542614", "mapreduce.output.fileoutputformat.compress": "true"}	["debug_000007"]											
	Bug-175	BUG	1	org.apache.hadoop.mapreduce.security.TestTokenCache#testBinaryCredentialsWithScheme	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.security.Credentials.readTokenStorageFile(Credentials.java:222), org.apache.hadoop.mapreduce.security.TokenCache.mergeBinaryTokens(TokenCache.java:158), org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:141), org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:109), org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme(TestTokenCache.java:74), org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme$$CONFUZZ(TestTokenCache.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.security.TestTokenCache/testBinaryCredentialsWithScheme/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1951950420", "io.file.buffer.size": "2010302139"}	["debug_000003"]											
	Bug-202	BUG	1	org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testUncompressedInputDefaultDelimiterPosValue	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312), org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue(TestLineRecordReader.java:601), org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testUncompressedInputDefaultDelimiterPosValue/campaign/failures/debug_000000	{"hadoop.security.groups.cache.secs": "933", "file.bytes-per-checksum": "1946709147"}	["debug_000000"]											
	invalid value	FP	1	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testFailAbortV1	java.lang.IllegalArgumentException	Illegal bufferSize	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42), org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56), org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134), org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70), org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testFailAbortV1/campaign/failures/debug_000005	{"mapreduce.output.fileoutputformat.compress": "true", "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.SnappyCodec", "io.compression.codec.snappy.buffersize": "0"}	["debug_000005"]											
	Bug-202	BUG	1	org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438), org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:310), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326), org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000007	{"io.file.buffer.size": "712074300", "file.stream-buffer-size": "2085334735", "mapreduce.output.fileoutputformat.compress": "true"}	["debug_000007"]											
[
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDataTransferProtocol",
        "testMethod": "testDataTransferProtocol",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol(TestDataTransferProtocol.java:346)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol$$CONFUZZ(TestDataTransferProtocol.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "34559"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDataTransferProtocol",
        "testMethod": "testDataTransferProtocol",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 191619180000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol(TestDataTransferProtocol.java:346)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol$$CONFUZZ(TestDataTransferProtocol.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "3193653,42695,9152757"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDataTransferProtocol",
        "testMethod": "testDataTransferProtocol",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol(TestDataTransferProtocol.java:346)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol$$CONFUZZ(TestDataTransferProtocol.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-10"
        ],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1125603642"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp37316493]@239678d{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@63214338{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-90"
        ],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "810024962"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-108"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "2h"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "9528"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1070492031"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 1073791040 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.reset(TestSnapshotPathINodes.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1073791040"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-107"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "167948301"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 1, volumes configured: 2, volumes failed: 1, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "23784",
            "dfs.datanode.disk.check.timeout": "097ms"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "22342"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-6"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "559017483"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.io.IOException",
        "errorMessage": "Unexpected configuration parameters: dfs.namenode.replication.min = 12255 > dfs.replication.max = 622",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:532)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "12255"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-106"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "6403d"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-12"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1627054902"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedBeforeStandbyRestart",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSimpleProxyAuthParamsInUrl",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[d[oas=test-proxy-user, op=GETFILESTATUS, user.name=test-user]]> but was:<[d[elegation=IwAPdGVzdC1wcm94eS11c2VyAACKAYlpWb1ligGJboAZZQEBFGd9M0RjnYu8jAIrTWNBv3bpxMqrEldFQkhERlMgZGVsZWdhdGlvbgsxMjcuMC4wLjE6MA, op=GETFILESTATUS]]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.checkQueryParams(TestWebHdfsUrl.java:372)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl(TestWebHdfsUrl.java:124)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSimpleProxyAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl(TestWebHdfsUrl.java:119)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true",
            "fs.webhdfs.impl.disable.cache": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSimpleProxyAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl(TestWebHdfsUrl.java:119)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-166"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileChecksumAfterDecommission",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1683401871",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.<init>(DFSStripedOutputStream.java:293)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:315)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:432)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission$$CONFUZZ(TestDecommissionWithStriped.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "1244611113"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS",
        "testMethod": "testRestartAfterReencrypt",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryption.setup(TestReencryption.java:129)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.setup(TestReencryptionWithKMS.java:60)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "32702"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-156"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "java.io.IOException",
        "errorMessage": "Failed: the number of failed blocks = 4 > the number of parity blocks = 3",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:410)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleStreamerFailure(DFSStripedOutputStream.java:435)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.flushAllInternals(DFSStripedOutputStream.java:1336)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1239)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:904)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommissionWithBusyNode(TestDecommissionWithStriped.java:303)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommissionWithBusyNode$$CONFUZZ(TestDecommissionWithStriped.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client-write-packet-size": "229282775",
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 14980. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "14980"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalCommonDirAcrossNameSpace",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=27509 < max=200 for QueuedThreadPool[qtp565352670]@21b298de{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58211c07{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "27506"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-105"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2139792275"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "15"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-1"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1987432512"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-12"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "273801683",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "270041727"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.31234157).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.312341570854187"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '16777487ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "16777487ms"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-104"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.io.IOException",
        "errorMessage": "Tried to read 1 byte(s) past the limit at offset 8",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.checkLimit(FSEditLogLoader.java:1352)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.read(FSEditLogLoader.java:1359)",
            "java.base/java.io.DataInputStream.readByte(DataInputStream.java:270)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOpFrame(FSEditLogOp.java:5237)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOp(FSEditLogOp.java:5198)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$Reader.readOp(FSEditLogOp.java:5071)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOpImpl(EditLogFileInputStream.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOp(EditLogFileInputStream.java:276)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:201)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:915)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:762)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:339)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2246)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNodes(MiniDFSCluster.java:2201)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshot1(TestSnapshotDeletion.java:606)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshot1$$CONFUZZ(TestSnapshotDeletion.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.op.size": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-53"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1543707946",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "945099495m"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.sleep(Native Method)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2771)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2820)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1795)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.heartbeat.recheck-interval": "1693287612"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.sleep(Native Method)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:973)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "app//org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "app//org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "app//org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:932)",
            "app//org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359)",
            "app//org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteHalfABlock(FileSystemContractBaseTest.java:333)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testWriteReadAndDeleteHalfABlock$$CONFUZZ(TestHDFSFileSystemContract.java)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.block.write.locateFollowingBlock.initial.delay.ms": "343185681"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-110"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setConnectTimeout(HttpURLConnection.java:3304)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:64)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getContentSummary(WebHdfsFileSystem.java:1886)",
            "org.apache.hadoop.hdfs.TestQuota.testBlockAllocationAdjustsUsageConservatively(TestQuota.java:1098)",
            "org.apache.hadoop.hdfs.TestQuota.testBlockAllocationAdjustsUsageConservatively$$CONFUZZ(TestQuota.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.connect-timeout": "1809h"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loginAsNameNodeUser(NameNode.java:719)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:738)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "org.apache.hadoop.hdfs.qjournal.client.QuorumException",
        "errorMessage": "Could not format one or more JournalNodes. 3 exceptions thrown:127.0.0.1:37513: Call From 04c076bd0267/172.17.0.2 to localhost:37513 failed on socket timeout exception: java.net.SocketTimeoutException: 31 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:33628 remote=/127.0.0.1:37513]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout127.0.0.1:39373: Call From 04c076bd0267/172.17.0.2 to localhost:39373 failed on socket timeout exception: java.net.SocketTimeoutException: 31 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:39670 remote=/127.0.0.1:39373]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout127.0.0.1:33647: Call From 04c076bd0267/172.17.0.2 to localhost:33647 failed on socket timeout exception: java.net.SocketTimeoutException: 31 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:42316 remote=/127.0.0.1:33647]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:264)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:117)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.client.rpc-timeout.ms": "31"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Time out while waiting for journal node 0 to start.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:262)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjm.operations.timeout": "49933592h"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 30166). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "30166"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testObserverToActive",
        "failure": "java.net.UnknownHostException",
        "errorMessage": "namenode0.test",
        "stackTrace": [
            "java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)",
            "java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllByDomainName(DNSDomainNameResolver.java:33)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllResolvedHostnameByDomainName(DNSDomainNameResolver.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getResolvedHostsIfNecessary(AbstractNNFailoverProxyProvider.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getProxyAddresses(AbstractNNFailoverProxyProvider.java:183)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:51)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:45)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider.<init>(ObserverReadProxyProvider.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$2.<init>(TestObserverReadProxyProvider.java:116)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.setupProxyProvider(TestObserverReadProxyProvider.java:106)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive(TestObserverReadProxyProvider.java:219)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.resolve-needed.testcluster": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-125"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testObserverToActive",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "No writes!",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$NameNodeAnswer$ClientProtocolAnswer.answer(TestObserverReadProxyProvider.java:398)",
            "org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39)",
            "org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96)",
            "org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)",
            "org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126)",
            "org.apache.hadoop.hdfs.protocol.ClientProtocol$MockitoMock$494868196.reportBadBlocks(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider$ObserverReadInvocationHandler.invoke(ObserverReadProxyProvider.java:519)",
            "com.sun.proxy.$Proxy36.reportBadBlocks(Unknown Source)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doWrite(TestObserverReadProxyProvider.java:341)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doWrite(TestObserverReadProxyProvider.java:332)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive(TestObserverReadProxyProvider.java:238)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testBothNodesInStandbyState",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected non-empty /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000012",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.assertNNHasCheckpoints(FSImageTestUtil.java:515)",
            "org.apache.hadoop.hdfs.server.namenode.ha.HATestUtil.waitForCheckpoint(HATestUtil.java:347)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.testBothNodesInStandbyState(TestStandbyCheckpoints.java:245)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.testBothNodesInStandbyState$$CONFUZZ(TestStandbyCheckpoints.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.standby.checkpoints": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=931) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testUMaskDefaultAclNewFile(FSAclBaseTest.java:934)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testUMaskDefaultAclNewFile$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "931"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-103"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "520060671"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.net.BindException",
        "errorMessage": "Address already in use",
        "stackTrace": [
            "java.base/sun.nio.ch.Net.bind0(Native Method)",
            "java.base/sun.nio.ch.Net.bind(Net.java:459)",
            "java.base/sun.nio.ch.Net.bind(Net.java:448)",
            "java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)",
            "java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)",
            "org.apache.hadoop.ipc.Server.bind(Server.java:631)",
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1233)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2246)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2227)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock(TestHASafeMode.java:840)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock$$CONFUZZ(TestHASafeMode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.reuseaddr": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-73"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSUtil.getBindAddress(DFSUtil.java:1191)",
            "org.apache.hadoop.hdfs.server.aliasmap.InMemoryLevelDBAliasMapServer.start(InMemoryLevelDBAliasMapServer.java:82)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startAliasMapServerIfNecessary(NameNode.java:809)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:769)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.provided.aliasmap.inmemory.enabled": "true",
            "dfs.namenode.provided.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 2, volumes failed: 2, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "4ms"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-28"
        ],
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1077903103"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-65"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testBasicReplication",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getInServiceXceiverAverageByStorageType(BlockPlacementPolicyDefault.java:1044)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getInServiceXceiverAverage(BlockPlacementPolicyDefault.java:1023)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.excludeNodeByLoad(BlockPlacementPolicyDefault.java:1000)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.isGoodDatanode(BlockPlacementPolicyDefault.java:1086)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:855)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:774)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:566)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:478)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:350)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:170)",
            "org.apache.hadoop.hdfs.server.blockmanagement.ReplicationWork.chooseTargets(ReplicationWork.java:51)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:2031)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.scheduleSingleReplication(TestBlockManager.java:641)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.doBasicTest(TestBlockManager.java:230)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testBasicReplication(TestBlockManager.java:221)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testBasicReplication$$CONFUZZ(TestBlockManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.redundancy.considerLoadByStorageType": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testBasicReplication",
        "failure": "java.io.IOException",
        "errorMessage": "Unexpected configuration parameters: dfs.namenode.maintenance.replication.min = 560 > dfs.replication = 180",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:580)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.setupMockCluster(TestBlockManager.java:170)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.maintenance.replication.min": "560"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testSafeModeIBR",
        "failure": "org.apache.hadoop.hdfs.server.blockmanagement.UnresolvedTopologyException",
        "errorMessage": "Unresolved topology mapping for host host",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocation(DatanodeManager.java:1030)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:1250)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testSafeModeIBR(TestBlockManager.java:912)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testSafeModeIBR$$CONFUZZ(TestBlockManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reject-unresolved-dn-topology-mapping": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-105"
        ],
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testStickyBitRecursiveDeleteFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "639821933",
            "ipc.server.handler.queue.size": "2141282303"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Cannot create directory /. Name node is in safe mode.The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1081223 live datanodes to reach the minimum number 1081223.Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3404) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1159) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:740) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy26.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:674)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy27.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507)",
            "org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2483)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1485)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1482)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1499)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1474)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:456)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:305)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "1081223"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=26592) must divide block size (=912).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:305)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "912"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 3 is less than the required minimum of 29 for /srcdat/seven/four/4824355616721279605, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFiles(DFSTestUtil.java:411)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFiles(DFSTestUtil.java:368)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:221)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "29"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:245)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.extension.testing": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected getfileinfo event not found in audit log",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.verifyAuditLogs(TestFsck.java:281)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:228)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.audit.log.token.tracking.id": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin",
        "testMethod": "testTransitionToStandby",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<0> but was:<-1>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:120)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testTransitionToStandby(TestDFSHAAdmin.java:283)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testTransitionToStandby$$CONFUZZ(TestDFSHAAdmin.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.automatic-failover.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=767).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testGetAclStatusRequiresTraverseOrSuper(FSAclBaseTest.java:1405)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testGetAclStatusRequiresTraverseOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 171437102for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 450000",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "171437102"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-31"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.initializeCacheExecutor(FsVolumeImpl.java:213)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.<init>(FsVolumeImpl.java:184)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder.build(FsVolumeImplBuilder.java:93)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addVolume(FsDatasetImpl.java:486)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:371)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 33287. Value configured is either less than maxVolumeFailureLimit or greater than to the number of configured volumes (1).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:331)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "33287"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Exception while testing testMoveBlockFailure",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure(TestFsDatasetImpl.java:1003)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "899"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-126"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure(TestFsDatasetImpl.java:1005)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "1468568631"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-11"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame",
        "testMethod": "testNameNodeXFrameOptionsDisabled",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.createServerwithXFrame(TestNameNodeHttpServerXFrame.java:92)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled(TestNameNodeHttpServerXFrame.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled$$CONFUZZ(TestNameNodeHttpServerXFrame.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "841301670"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-102"
        ],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setReadTimeout(HttpURLConnection.java:3349)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:65)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:717)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.create(WebHdfsFileSystem.java:1521)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testModifyAclEntriesOnlyAccess(FSAclBaseTest.java:152)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testModifyAclEntriesOnlyAccess$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.read-timeout": "377895d"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-156"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.io.IOException",
        "errorMessage": "Failed: the number of failed blocks = 4 > the number of parity blocks = 3",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:410)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleStreamerFailure(DFSStripedOutputStream.java:435)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleCurrentStreamerFailure(DFSStripedOutputStream.java:427)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.writeParity(DFSStripedOutputStream.java:1186)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.writeParityCells(DFSStripedOutputStream.java:1142)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1234)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:904)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommission(TestDecommissionWithStriped.java:463)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileSmallerThanOneStripe(TestDecommissionWithStriped.java:196)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor.testFileSmallerThanOneStripe$$CONFUZZ(TestDecommissionWithStripedBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-2"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-793720479",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeConfigFile(TestDecommissionWithStriped.java:585)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:126)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1343464601"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testNoLogs",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Image file check. expected:<[/foo1/current/fsimage_0000000000000000100,/foo1/current/fsimage_0000000000000000200]> but was:<[]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:314)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testNoLogs(TestNNStorageRetentionManager.java:143)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testNoLogs$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "1075872255"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList",
        "testMethod": "testDfsReservedForDifferentStorageTypes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<100> but was:<605688075>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testDfsReservedForDifferentStorageTypes(TestFsVolumeList.java:196)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testDfsReservedForDifferentStorageTypes$$CONFUZZ(TestFsVolumeList.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.disk": "605688075"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashBetweenSyncLogAndPersistPaxosData",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=3 < max=3 for QueuedThreadPool[qtp1844339839]@6dee647f{STARTED,3<=3<=3,i=3,r=-1,q=0}[ReservedThreadExecutor@5fea6cdb{s=0/1,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "3"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-156"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /encFile could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-29"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler$ReencryptionBatch.<init>(ReencryptionHandler.java:488)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.<init>(ReencryptionHandler.java:248)",
            "org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager.<init>(EncryptionZoneManager.java:250)",
            "org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:411)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:977)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reencrypt.batch.size": "1640153608"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.AssertionError",
        "errorMessage": "setXAttr should have thrown",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest$17.run(FSXAttrBaseTest.java:1052)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.testRawXAttrs(FSXAttrBaseTest.java:1036)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr.testRawXAttrs$$CONFUZZ(TestFileContextXAttr.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.enabled": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-2"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:89)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2147483390"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-7"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:89)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.block.deletion.increment must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:1008)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.block.deletion.increment": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby",
        "testMethod": "testSharedEditsMissingLogs",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "15"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-108"
        ],
        "testClass": "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal",
        "testMethod": "testStatisticsForErasureCodingRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead(TestBlockReaderLocal.java:822)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead$$CONFUZZ(TestBlockReaderLocal.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "31961985d",
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "8197723s"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-64"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock",
        "testMethod": "testFSWriteLockReportSuppressed",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.addMetric(FSNamesystemLock.java:359)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:287)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:236)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock.testFSWriteLockReportSuppressed(TestFSNamesystemLock.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock.testFSWriteLockReportSuppressed$$CONFUZZ(TestFSNamesystemLock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.lock.detailed-metrics.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesFileRecursive",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.volumes.replica-add.threadpool.size": "291594243"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Permission denied. user=super is not the owner of inode=/p31/bruce/file at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkOwner(FSPermissionChecker.java:409) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:360) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370) at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240) at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943) at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1927) at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkOwner(FSDirectory.java:1872) at org.apache.hadoop.hdfs.server.namenode.FSDirAclOp.removeAclEntries(FSDirAclOp.java:74) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeAclEntries(FSNamesystem.java:7659) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.removeAclEntries(NameNodeRpcServer.java:2164) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.removeAclEntries(ClientNamenodeProtocolServerSideTranslatorPB.java:1530) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.removeAclEntries(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.removeAclEntries(ClientNamenodeProtocolTranslatorPB.java:1517)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.removeAclEntries(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.removeAclEntries(DFSClient.java:2709)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$48.doCall(DistributedFileSystem.java:2612)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$48.doCall(DistributedFileSystem.java:2609)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.removeAclEntries(DistributedFileSystem.java:2621)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1347)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.superusergroup": "xqvbuyuvsroaflwbypttiapduwerdudtjucklrlsgmjjnphlilzxxftdclxocdxaghpdkswibaggroup"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteOneBlock",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.start0(Native Method)",
            "java.base@11.0.19/java.lang.Thread.start(Thread.java:798)",
            "app//org.apache.hadoop.ipc.Server.start(Server.java:3422)",
            "app//org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:2686)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1789)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "20290"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement",
        "testMethod": "testBlockMoveAcrossStorageInSameNode",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode(TestBlockReplacement.java:294)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode$$CONFUZZ(TestBlockReplacement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.block.access.token.enable": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor",
        "testMethod": "testDecommissionDeadDN",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.createCluster(TestDecommissioningStatus.java:122)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.setUp(TestDecommissioningStatusWithBackoffMonitor.java:68)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "334533507"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-109"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.hdfs.DFSUtilClient.getThreadPoolExecutor(DFSUtilClient.java:949)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.initializeStripedBlkReconstructionThreadPool(ErasureCodingWorker.java:109)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:70)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.threads": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-156"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones",
        "testMethod": "testTrashExpunge",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /zone41/encFile61 could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy77.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy78.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer.cipher.suites": "NoPadding",
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand",
        "testMethod": "testRunMultipleCommandsUnderOneSetup",
        "failure": "java.io.IOException",
        "errorMessage": "Failed to save in any storage directories while saving namespace.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(FSImage.java:1243)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(FSImage.java:1200)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.format(FSImage.java:191)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.setUp(TestDiskBalancerCommand.java:96)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2139128575",
            "dfs.namenode.top.enabled": "false",
            "dfs.replication.max": "12487",
            "dfs.image.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testWebHdfsAllowandDisallowSnapshots",
        "failure": "java.io.IOException",
        "errorMessage": "Content-Type \"text/html;charset=iso-8859-1\" is incompatible with \"application/json\" (parsed=\"text/html; charset=iso-8859-1\")",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.jsonParse(WebHdfsFileSystem.java:484)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.allowSnapshot(WebHdfsFileSystem.java:1339)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots(TestWebHDFS.java:541)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "7"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.DFSTestUtil.setupCluster(DFSTestUtil.java:2491)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.setupCluster(TestErasureCodingMultipleRacks.java:96)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:131)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-157"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.directoryscan.threads": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsPathWithSemicolon",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 8 for /a;b, clientName=127.0.0.1        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsPathWithSemicolon(TestWebHdfsUrl.java:524)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsPathWithSemicolon$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "8"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-32"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testCreateSymlink",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA$CreateSymlinkOp.prepare(TestRetryCacheWithHA.java:678)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testClientRetryWithFailover(TestRetryCacheWithHA.java:1303)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testCreateSymlink(TestRetryCacheWithHA.java:1218)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testCreateSymlink$$CONFUZZ(TestRetryCacheWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testSecondaryPurgesEditLogs",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Edit log files were not purged from 2NN expected:<1> but was:<5>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs(TestCheckpoint.java:2282)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "13312"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Must set a positive value for dfs.namenode.decommission.blocks.per.interval",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager.activate(DatanodeAdminManager.java:125)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.activate(DatanodeManager.java:451)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.activate(BlockManager.java:740)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:870)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.decommission.blocks.per.interval": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestClusterId",
        "testMethod": "testFormatWithNonInteractive",
        "failure": "org.apache.hadoop.hdfs.server.namenode.NameNodeFormatException",
        "errorMessage": "NameNode format aborted as reformat is disabled for this cluster.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1267)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1726)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithNonInteractive(TestClusterId.java:331)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithNonInteractive$$CONFUZZ(TestClusterId.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.reformat.disabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "java.io.IOException: Unexpected configuration parameters: dfs.namenode.replication.min = 29171 > dfs.replication.max = 930 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:532) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796) at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256) at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450) at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261) at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132) at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016) at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948) at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576) at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518) at org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:151) at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348) at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65) at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100) at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208) at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:173)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "29171"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameNodeFiles(TestStartup.java:264)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:350)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.replication.min": "803"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures",
        "testMethod": "testCheckingClosedVolume",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.disk.check.timeout - 0 (should be > 0)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker.<init>(DatasetVolumeChecker.java:125)",
            "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures.testCheckingClosedVolume(TestDatasetVolumeCheckerFailures.java:104)",
            "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures.testCheckingClosedVolume$$CONFUZZ(TestDatasetVolumeCheckerFailures.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "0m"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling",
        "testMethod": "testHeartbeatStopWatch",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertFalse(Assert.java:65)",
            "org.junit.Assert.assertFalse(Assert.java:75)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling.testHeartbeatStopWatch(TestHeartbeatHandling.java:278)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling.testHeartbeatStopWatch$$CONFUZZ(TestHeartbeatHandling.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.interval": "83",
            "dfs.namenode.avoid.write.stale.datanode": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testAddVolumeWithSameStorageUuid",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 500for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 172",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "344"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.deleteAndEnsureInTrash(TestDataNodeRollingUpgrade.java:141)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:274)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.startup.delay.block.deletion.sec": "20403"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "java.io.IOException",
        "errorMessage": "Unable to close file because the last block BP-1587010755-172.17.0.2-1689689423354:blk_1073741826_1002 does not have enough number of replicas.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:969)",
            "org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.TestDFSShell.writeFile(TestDFSShell.java:141)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu(TestDFSShell.java:257)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "537362175",
            "dfs.blockreport.incremental.intervalMsec": "128317504"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleDatanodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes(TestSortLocatedBlock.java:197)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "1867501415"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-59"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleDatanodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)",
            "java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)",
            "java.base/java.util.TimSort.sort(TimSort.java:220)",
            "java.base/java.util.Arrays.sort(Arrays.java:1515)",
            "java.base/java.util.ArrayList.sort(ArrayList.java:1750)",
            "java.base/java.util.Collections.sort(Collections.java:179)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.lambda$createSecondaryNodeSorter$0(DatanodeManager.java:654)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistance(NetworkTopology.java:983)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistanceUsingNetworkLocation(NetworkTopology.java:946)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlock(DatanodeManager.java:637)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:554)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes(TestSortLocatedBlock.java:188)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.read.considerStorageType": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testErrOutPut",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the number of requested top users must be at least 1",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:237)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.num.users": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-123"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA",
        "testMethod": "testHarUriWithHaUriWithNoPort",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort(TestHarFileSystemWithHA.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort$$CONFUZZ(TestHarFileSystemWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "5532"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-7"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testEnterSafeModeInANNShouldNotThrowNPE",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:114)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:456)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:447)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:447)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.copyNameDirs(MiniDFSCluster.java:1326)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1121)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1882163822"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestLease",
        "testMethod": "testFactory",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid checksum type: userOpt=null, default=CRC32C:0, effective=null",
        "stackTrace": [
            "org.apache.hadoop.hdfs.client.impl.DfsClientConf.createChecksum(DfsClientConf.java:395)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1273)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1155)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1134)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1105)",
            "org.apache.hadoop.hdfs.TestLease.createFsOut(TestLease.java:398)",
            "org.apache.hadoop.hdfs.TestLease.testFactory(TestLease.java:380)",
            "org.apache.hadoop.hdfs.TestLease.testFactory$$CONFUZZ(TestLease.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWhenStoragePolicySetToONESSD",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.createCluster(TestExternalStoragePolicySatisfier.java:194)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD(TestExternalStoragePolicySatisfier.java:480)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "170507386",
            "dfs.namenode.top.windows.minutes": "9596,8351,5998"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-54"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithCaching",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1187239463",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching(TestFileCreation.java:199)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "9281ms",
            "dfs.namenode.gc.time.monitor.observation.window.ms": "8011895h"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList",
        "testMethod": "testGetCachedVolumeCapacity",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<4000> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testGetCachedVolumeCapacity(TestFsVolumeList.java:429)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testGetCachedVolumeCapacity$$CONFUZZ(TestFsVolumeList.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.ram_disk": "18496"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.util.Preconditions.checkArgument(Preconditions.java:185)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService.<init>(FsDatasetAsyncDiskService.java:98)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:366)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException",
        "errorMessage": "Out of space: The volume with the most available space (=0 B) is less than the block size (=0 B).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:96)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:68)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy.doChooseVolume(AvailableSpaceVolumeChoosingPolicy.java:141)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy.chooseVolume(AvailableSpaceVolumeChoosingPolicy.java:129)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.chooseVolume(FsVolumeList.java:88)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.getNextVolume(FsVolumeList.java:118)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.createRbw(FsDatasetImpl.java:1476)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume(TestFsDatasetImpl.java:397)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.getspaceused.classname": "org.apache.hadoop.fs.DFCachingGetSpaceUsed",
            "dfs.datanode.fsdataset.volume.choosing.policy": "org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException",
        "errorMessage": "Out of space: The volume with the most available space (=0 B) is less than the block size (=0 B).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:96)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:68)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.chooseVolume(FsVolumeList.java:88)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.getNextVolume(FsVolumeList.java:118)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.createRbw(FsDatasetImpl.java:1476)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume(TestFsDatasetImpl.java:397)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.getspaceused.classname": "org.apache.hadoop.fs.DFCachingGetSpaceUsed"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-156"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend3",
        "testMethod": "testAppendToPartialChunk",
        "failure": "java.io.IOException",
        "errorMessage": "Could not get block locations. Source file \"/partialChunk/foo1\" - Aborting...block==null",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1525)",
            "org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend3",
        "testMethod": "testAppendToPartialChunk",
        "failure": "java.io.IOException",
        "errorMessage": "Unexpected configuration parameters: dfs.namenode.replication.min = 409 > dfs.replication.max = 50",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:532)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend3.setUp(TestFileAppend3.java:80)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.replication.max": "50",
            "dfs.namenode.replication.min": "409"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore",
        "testMethod": "testStorageRestoreFailure",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Cannot create directory /test. Name node is in safe mode.Resources are low on NN. Please add or free up more resourcesthen turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use \"hdfs dfsadmin -safemode leave\" to turn safe mode off. NamenodeHostName:localhost at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3404) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1159) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:740) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy27.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:674)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy28.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507)",
            "org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2483)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1485)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1482)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1499)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1474)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:405)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure$$CONFUZZ(TestStorageRestore.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator",
        "testMethod": "testReservedSpacePercentage",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1000> but was:<412851000>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.checkReserved(TestReservedSpaceCalculator.java:169)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage(TestReservedSpaceCalculator.java:91)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage$$CONFUZZ(TestReservedSpaceCalculator.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.pct.archive": "4128510"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator",
        "testMethod": "testReservedSpacePercentage",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1000> but was:<151170972000>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.checkReserved(TestReservedSpaceCalculator.java:169)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage(TestReservedSpaceCalculator.java:90)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage$$CONFUZZ(TestReservedSpaceCalculator.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.pct.ssd": "1511709720"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator",
        "testMethod": "testReservedSpacePercentage",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1000> but was:<26850073500>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.checkReserved(TestReservedSpaceCalculator.java:169)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage(TestReservedSpaceCalculator.java:89)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage$$CONFUZZ(TestReservedSpaceCalculator.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.pct.disk": "268500735"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=120) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclMustBeOwnerOrSuper(FSAclBaseTest.java:1386)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testSetAclMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "120"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart",
        "testMethod": "testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister",
        "failure": "java.io.IOException",
        "errorMessage": "Filesystem closed",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:494)",
            "org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1043)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:353)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister(TestFileLengthOnClusterRestart.java:55)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister$$CONFUZZ(TestFileLengthOnClusterRestart.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.trash.interval": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[4.4.4.4]> but was:<[3.3.3.3]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:155)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "16085"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-59"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)",
            "java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)",
            "java.base/java.util.TimSort.sort(TimSort.java:220)",
            "java.base/java.util.Arrays.sort(Arrays.java:1515)",
            "java.base/java.util.ArrayList.sort(ArrayList.java:1750)",
            "java.base/java.util.Collections.sort(Collections.java:179)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.lambda$createSecondaryNodeSorter$0(DatanodeManager.java:654)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistance(NetworkTopology.java:983)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistanceUsingNetworkLocation(NetworkTopology.java:946)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlock(DatanodeManager.java:637)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:554)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "29697",
            "dfs.namenode.read.considerStorageType": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-33"
        ],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesStickyBit",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:2686)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1789)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "879558531"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-167"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs",
        "testMethod": "testNameEditsConfigsFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure(TestNameEditsConfigs.java:450)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure$$CONFUZZ(TestNameEditsConfigs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "251625215"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker",
        "testMethod": "testCheckAvailability",
        "failure": "java.lang.AssertionError",
        "errorMessage": "isResourceAvailable must return true if disk usage is lower than threshold",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testCheckAvailability(TestNameNodeResourceChecker.java:65)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testCheckAvailability$$CONFUZZ(TestNameNodeResourceChecker.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "70081660"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-120"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcAfterJNRestart",
        "failure": "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$PrematureEOFException",
        "errorMessage": "got premature end-of-file at txid 0; expected file to go up to 10",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:209)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.qjournal.QJMTestUtil.verifyEdits(QJMTestUtil.java:130)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcAfterJNRestart(TestQuorumJournalManager.java:1119)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcAfterJNRestart$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.simple.anonymous.allowed": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testAppend",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.sleep(Native Method)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:973)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "app//org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "app//org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "app//org.apache.hadoop.hdfs.AppendTestUtil.testAppend(AppendTestUtil.java:257)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testAppend(TestHDFSFileSystemContract.java:68)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testAppend$$CONFUZZ(TestHDFSFileSystemContract.java)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blockreport.incremental.intervalMsec": "512"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testRetainExtraLogs",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Check old edits are removed. expected:<...-0000000000000000200[]> but was:<...-0000000000000000200[,/foo2/current/edits_0000000000000000201-0000000000000000300]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:323)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testRetainExtraLogs(TestNNStorageRetentionManager.java:205)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testRetainExtraLogs$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.extra.edits.segments.retained": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 269651711        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1342)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "269651711"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testComplexFailoverIntoSafemode",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 2, volumes failed: 2, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "615ms",
            "ipc.server.read.threadpool.size": "3522"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot",
        "testMethod": "testXAttrForSnapshotRootAfterChange",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Cannot add additional XAttr to inode, would exceed limit of 1 at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:398) at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:274) at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:89) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:8271) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2282) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1709) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.setXAttr(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setXAttr(ClientNamenodeProtocolTranslatorPB.java:1741)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.setXAttr(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.setXAttr(DFSClient.java:2866)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$58.doCall(DistributedFileSystem.java:2912)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$58.doCall(DistributedFileSystem.java:2908)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.setXAttr(DistributedFileSystem.java:2921)",
            "org.apache.hadoop.fs.FileSystem.setXAttr(FileSystem.java:3104)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.testXAttrForSnapshotRootAfterChange(TestXAttrWithSnapshot.java:209)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.testXAttrForSnapshotRootAfterChange$$CONFUZZ(TestXAttrWithSnapshot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.max-xattrs-per-inode": "1"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSOutputStream",
        "testMethod": "testEndLeaseCall",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Exceeded the configured number of objects 1 in the filesystem. at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkFsObjectLimit(FSNamesystem.java:5167) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:393) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2703) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.TestDFSOutputStream.testEndLeaseCall(TestDFSOutputStream.java:427)",
            "org.apache.hadoop.hdfs.TestDFSOutputStream.testEndLeaseCall$$CONFUZZ(TestDFSOutputStream.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.objects": "1"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.mover.TestMover",
        "testMethod": "testMoverCliWithFederationHA",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.batched.ls.limit must be greater than zero",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:914)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverCliWithFederationHA(TestMover.java:583)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverCliWithFederationHA$$CONFUZZ(TestMover.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.batched.ls.limit": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-189"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedBlockRead",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161)",
            "org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)",
            "org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)",
            "org.apache.hadoop.hdfs.server.datanode.ProvidedReplica.getDataInputStream(ProvidedReplica.java:191)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockInputStreamWithCheckingPmemCache(FsDatasetImpl.java:859)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockInputStream(FsDatasetImpl.java:836)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testProvidedBlockRead(TestProvidedImpl.java:424)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testProvidedBlockRead$$CONFUZZ(TestProvidedImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2147417854"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-156"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestMultipleNNPortQOP",
        "testMethod": "testAuxiliaryPortSendingQOP",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /filetestAuxiliaryPortSendingQOPPrimary could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer.cipher.suites": "AES"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodesAfterModification",
        "failure": "java.io.IOException",
        "errorMessage": "Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-143100b1-1780-4e37-94ae-0c178b8d113b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-143100b1-1780-4e37-94ae-0c178b8d113b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1352)",
            "org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1420)",
            "org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1646)",
            "org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1547)",
            "org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:717)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.overwrite.downstream.derived.qop": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-168"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat",
        "testMethod": "testBackwardsCompat",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Exception occurred before anything was written: java.lang.NullPointerException; nulljava.lang.NullPointerException at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:814) at org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:195) at org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java) at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59) at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299) at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293) at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) at java.base/java.lang.Thread.run(Thread.java:829)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.failWithException(TestDataXceiverBackwardsCompat.java:74)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:222)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.overwrite.downstream.derived.qop": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<200> but was:<401>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.DFSTestUtil.urlGetBytes(DFSTestUtil.java:1003)",
            "org.apache.hadoop.hdfs.DFSTestUtil.urlGet(DFSTestUtil.java:993)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testHttpServer(TestJournalNode.java:318)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testHttpServer$$CONFUZZ(TestJournalNode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.simple.anonymous.allowed": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-157"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testScannerWithProvidedVolumes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "java.base/java.util.concurrent.Executors.newFixedThreadPool(Executors.java:155)",
            "org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.<init>(DirectoryScanner.java:316)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testScannerWithProvidedVolumes(TestProvidedImpl.java:604)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testScannerWithProvidedVolumes$$CONFUZZ(TestProvidedImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.directoryscan.threads": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.io.IOException",
        "errorMessage": "localhost:0: Access denied: dfs.http.policy is HTTPS_ONLY.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:710)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1767)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:377)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:598)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:626)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:83)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos",
            "dfs.http.policy": "HTTPS_ONLY"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.net.ConnectException",
        "errorMessage": "localhost:0: Connection refused (Connection refused)",
        "stackTrace": [
            "java.base/java.net.PlainSocketImpl.socketConnect(Native Method)",
            "java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)",
            "java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)",
            "java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)",
            "java.base/java.net.Socket.connect(Socket.java:609)",
            "java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177)",
            "java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:507)",
            "java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:602)",
            "java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:275)",
            "java.base/sun.net.www.http.HttpClient.New(HttpClient.java:374)",
            "java.base/sun.net.www.http.HttpClient.New(HttpClient.java:395)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1253)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1187)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1081)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1015)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:789)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1767)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:377)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:598)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:626)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:83)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-110"
        ],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setConnectTimeout(HttpURLConnection.java:3304)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:64)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1767)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:377)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:598)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:626)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:83)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.connect-timeout": "49677h",
            "hadoop.security.authentication": "kerberos"
        }
    }
]
